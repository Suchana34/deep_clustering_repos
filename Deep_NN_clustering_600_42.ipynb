{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-NN_clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mxZOMIDXXau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import math\n",
        "import sys\n",
        "import logging\n",
        "#-----------------------------------------------------------\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from IPython.display import clear_output\n",
        "from scipy.spatial.distance import squareform, pdist\n",
        "from sklearn.preprocessing import normalize\n",
        "from numpy import linalg as LA\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from math import sqrt\n",
        "#----------------------------------------------\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from optparse import OptionParser\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqX8ZR5wsGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardization(X):\n",
        "    return normalize(X, axis=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKho_sESzQMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laplacian(A):\n",
        "    S = np.sum(A, 0)\n",
        "    D = np.diag(S)\n",
        "    D = LA.matrix_power(D, -1)\n",
        "    L = np.dot(D, A)\n",
        "    return L"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUSpsQozS-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization(V):\n",
        "    return (V - min(V)) / (max(V) - min(V))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndbmGyJzWIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Correlation_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'correlation')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHrGqwRnzY-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cosine_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'cosine')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV0iHGWzcp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Similarity_Dataset_Iterator():\n",
        "    def __init__(self, data, labels, similarity):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.matrix = similarity.get_matrix(data)\n",
        "        self.data_size = self.matrix.shape[0]\n",
        "        self.current_index = 0\n",
        "    def next_batch(self, num):\n",
        "        data=self.matrix.transpose()\n",
        "        labels=self.labels\n",
        "        idx = np.arange(0 , len(data))\n",
        "        np.random.shuffle(idx)\n",
        "        idx = idx[:num]\n",
        "        data_shuffle = [data[ i] for i in idx]\n",
        "        labels_shuffle = [labels[ i] for i in idx]\n",
        "        return data_shuffle, labels_shuffle\n",
        "    def whole_dataset(self):\n",
        "        return (self.matrix.transpose(), self.labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n076atQh0kmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4694b0f3-3b5c-4499-a529-d8cf00cb9b45"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3U9x9aT05Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6449bcd8-47ba-4954-884f-d3ec8ce644e5"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/edited_topics_all_news.csv')\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  processed_topic\n",
              "0           0  ...      west bengal\n",
              "1           1  ...      west bengal\n",
              "2           2  ...      west bengal\n",
              "3           3  ...      west bengal\n",
              "4           4  ...      west bengal\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0GlS3WC1Udh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.dropna(subset=['content'], inplace = True)\n",
        "#df.dropna(subset=['topic'], inplace = True)\n",
        "df['your column name'].isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dat6uH3E2OmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cced1ae-d391-4f6d-f054-a8e03a90c9ed"
      },
      "source": [
        "#len(df.content.unique()),  len(df.content), len(df.topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1204, 1304, 1304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S87soJgE2SZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "54489033-c90a-4c52-d068-6f818c65f370"
      },
      "source": [
        "#df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_id          0\n",
              "topic        0\n",
              "heading    383\n",
              "content      0\n",
              "tags        68\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PbPTbyu2deC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065c554a-dd09-4d56-8748-16017fc69e32"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1274, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0qrfJGtSkVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "552ce829-8343-47c7-9a26-e9b18dae90d0"
      },
      "source": [
        "np.unique(df.processed_topic[:600]).shape[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-XKjCAS48pD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3ad50f97-3371-499a-d3ab-f8d4bcf72e1f"
      },
      "source": [
        "#import re\n",
        "\n",
        "#import gensim\n",
        "#from gensim import corpora,models\n",
        "#from gensim.utils import simple_preprocess\n",
        "#from gensim.models import CoherenceModel\n",
        "#from gensim.parsing.preprocessing import STOPWORDS\n",
        "#from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "#from nltk.stem.porter import *\n",
        "#import numpy as np\n",
        "#np.random.seed(2018)\n",
        "\n",
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2dezj2a48qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemmer = SnowballStemmer(language='english',ignore_stopwords=True)\n",
        "#def lemmatize_stemming(text):\n",
        "#    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "#def preprocess(text):\n",
        "    #result = []\n",
        "   # for token in gensim.utils.simple_preprocess(text):\n",
        "   #     if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "   #         result.append(lemmatize_stemming(token))\n",
        "  #  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws57P9WE48uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "3eb64829-6726-4133-b90f-7e0f43b0be4e"
      },
      "source": [
        "#doc_sample = df['content'][0]\n",
        "#print('original document: ')\n",
        "#words = []\n",
        "#for word in doc_sample.split(' '):\n",
        "#    words.append(word)\n",
        "#print(words)\n",
        "#print('\\n\\n tokenized and lemmatized document: ')\n",
        "#print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['[\"Garbage-lined', 'streets', 'and', 'overflowing', 'drains', 'across', 'Salt', 'Lake', 'have', 'sparked', 'fear', 'of', 'an', 'outbreak', 'of', 'enteric', 'diseases', 'and', 'are', 'forcing', 'residents', 'to', 'keep', 'the', 'windows', 'and', 'doors', 'of', 'their', 'houses', 'firmly', 'shut.\",\"Residents', 'said', 'most', 'of', 'the', '150', 'tonnes', 'of', 'the', 'garbage', 'Salt', 'Lake', 'generates', 'every', 'day', 'is', 'accumulating', 'across', 'the', '33.5sq', 'km', 'township.\",\"“At', 'this', 'rate,', 'Salt', 'Lake', 'will', 'soon', 'become', 'Dhapa.', 'This', 'is', 'happening', 'at', 'a', 'time', 'the', 'authorities', 'as', 'well', 'as', 'residents', 'need', 'to', 'focus', 'on', 'hygiene', 'to', 'combat', 'Covid', 'and', 'dengue,”', 'said', 'a', 'resident,', 'hand', 'firmly', 'on', 'his', 'nose.\",\"“It', 'is', 'true', 'that', 'garbage', 'has', 'accumulated', 'in', 'some', 'places', 'but', 'I', 'don’t', 'think', 'it', 'is', 'a', 'big', 'problem.', 'We', 'will', 'clear', 'it', 'within', 'seven', 'days,”', 'said', 'Debasish', 'Jana,', 'the', 'mayoral', 'council', 'member', 'in', 'charge', 'of', 'solid', 'waste', 'management', 'at', 'the', 'Bidhannagar', 'Municipal', 'Corporation.\",\"Asked', 'why', 'the', 'civic', 'body', 'has', 'not', 'yet', 'been', 'able', 'to', 'solve', 'a', '“simple', 'problem”,', 'Jana', 'said:', '“Several', 'of', 'our', 'trucks', 'are', 'out', 'of', 'order,', 'but', 'our', 'sweepers', 'are', 'at', 'work', 'all', 'day.', 'It’s', 'just', 'that', 'accumulated', 'garbage', 'isn’t', 'being', 'removed', 'regularly', 'from', 'a', 'few', 'areas.”\",\"For', 'five', 'days', 'a', 'week,', 'Buddhadeb', 'Basu,', 'a', 'resident', 'of', 'DB', 'block,', 'near', 'City', 'Centre,', 'is', 'having', 'to', 'dump', 'household', 'waste', 'at', 'the', 'neighbourhood', 'compactor', 'station', 'overflowing', 'with', 'garbage.', 'He', 'doesn’t', 'have', 'a', 'choice.', 'His', 'neighbours,', 'too,', 'are', 'doing', 'the', 'same.\",\"“Civic', 'workers', 'would', 'previously', 'collect', 'garbage', 'from', 'our', 'doorstep', 'every', 'day.', 'Now', 'they', 'come', 'hardly', 'twice', 'a', 'week.', 'They', 'are', 'not', 'even', 'taking', 'away', 'garbage', 'from', 'near', 'the', 'compactor', 'station.', 'The', 'entire', 'area', 'stinks,”', 'the', '62-year-old', 'told', '\",\"The', 'Telegraph\",\".\",\"This', 'newspaper', 'drove', 'around', 'the', 'township', 'on', 'Monday', 'and', 'found', 'scarcely', 'any', 'block', 'or', 'compactor', 'station', 'that', 'did', 'not', 'have', 'a', 'heap', 'of', 'garbage', 'lying', 'around.\",\"The', 'areas', 'near', 'City', 'Centre', 'and', 'the', 'CGO', 'Complex', 'looked', 'the', 'dirtiest.', 'The', 'situation', 'was', 'similar', 'in', 'the', 'AE,', 'AB,', 'BC,', 'BB,', 'and', 'IC', 'blocks.\",\"A', '20-metre', 'stretch', 'from', 'the', 'City', 'Centre', 'Metro', 'station', 'till', 'Bidhannagar', 'College', 'had', 'almost', 'half', 'the', 'carriageway', 'swallowed', 'by', 'garbage.', 'The', 'entire', 'area', 'had', 'flies', 'swarming', 'around,', 'while', 'several', 'dogs', 'and', 'cows', 'were', 'seen', 'rummaging', 'through', 'the', 'garbage', 'for', 'food.\",\"Passers-by', 'were', 'seen', 'holding', 'handkerchiefs', 'on', 'their', 'noses', 'despite', 'wearing', 'masks.\",\"“The', 'stench', 'from', 'the', 'garbage', 'in', 'front', 'of', 'our', 'house', 'is', 'so', 'overpowering', 'that', 'we', 'keep', 'the', 'windows', 'of', 'our', 'house', 'shut,”', 'said', 'Prakash', 'Agarwal,', 'a', 'resident', 'of', 'EC', 'Block.\",\"A', 'civic', 'official', 'blamed', 'the', 'combination', 'of', 'staff', 'shortage', 'and', 'defunct', 'garbage', 'collection', 'trucks', 'for', 'the', 'sorry', 'state', 'of', 'affairs.\\xa0', '“Many', 'men', 'are', 'not', 'reporting', 'for', 'work', 'out', 'of', 'fear', 'of', 'contracting', 'the', 'coronavirus', 'and', 'also', 'because', 'local', 'trains', 'are', 'not', 'running,”', 'the', 'official', 'said.', '“There', 'used', 'to', 'be', '250', 'sweepers.', 'Now,', 'there', 'are', 'only', 'half', 'that\\xa0number.”\",\"Mayoral', 'council', 'member', 'Jana', 'said', 'many', 'workers', 'who', 'were', 'involved', 'in', 'collection', 'of', 'garbage', 'were', 'now', 'selling', 'vegetables', 'or', 'involved', 'in', 'other', 'activities.', '“We', 'are', 'trying', 'to', 'hire', 'personnel', 'but', 'the', 'pandemic', 'is', 'coming', 'in', 'the', 'way,”', 'he', 'said.\",\"To', 'add', 'to', 'the', 'problem,', 'sources', 'said,', 'many', 'handcarts', 'and', 'vans', 'have', 'broken', 'down.\"]']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['garbag', 'line', 'street', 'overflow', 'drain', 'salt', 'lake', 'spark', 'fear', 'outbreak', 'enter', 'diseas', 'forc', 'resid', 'window', 'door', 'hous', 'firm', 'shut', 'resid', 'say', 'tonn', 'garbag', 'salt', 'lake', 'generat', 'accumul', 'township', 'rate', 'salt', 'lake', 'soon', 'dhapa', 'happen', 'time', 'author', 'resid', 'need', 'focus', 'hygien', 'combat', 'covid', 'dengu', 'say', 'resid', 'hand', 'firm', 'nose', 'true', 'garbag', 'accumul', 'place', 'think', 'problem', 'clear', 'seven', 'day', 'say', 'debasish', 'jana', 'mayor', 'council', 'member', 'charg', 'solid', 'wast', 'manag', 'bidhannagar', 'municip', 'corpor', 'ask', 'civic', 'bodi', 'abl', 'solv', 'simpl', 'problem', 'jana', 'say', 'truck', 'order', 'sweeper', 'work', 'accumul', 'garbag', 'remov', 'regular', 'area', 'day', 'week', 'buddhadeb', 'basu', 'resid', 'block', 'near', 'citi', 'centr', 'have', 'dump', 'household', 'wast', 'neighbourhood', 'compactor', 'station', 'overflow', 'garbag', 'choic', 'neighbour', 'civic', 'worker', 'previous', 'collect', 'garbag', 'doorstep', 'come', 'hard', 'twice', 'week', 'take', 'away', 'garbag', 'near', 'compactor', 'station', 'entir', 'area', 'stink', 'year', 'tell', 'telegraph', 'newspap', 'drive', 'township', 'monday', 'scarc', 'block', 'compactor', 'station', 'heap', 'garbag', 'lie', 'area', 'near', 'citi', 'centr', 'complex', 'look', 'dirtiest', 'situat', 'similar', 'block', 'metr', 'stretch', 'citi', 'centr', 'metro', 'station', 'till', 'bidhannagar', 'colleg', 'half', 'carriageway', 'swallow', 'garbag', 'entir', 'area', 'fli', 'swarm', 'dog', 'cow', 'see', 'rummag', 'garbag', 'food', 'passer', 'see', 'hold', 'handkerchief', 'nose', 'despit', 'wear', 'mask', 'stench', 'garbag', 'hous', 'overpow', 'window', 'hous', 'shut', 'say', 'prakash', 'agarw', 'resid', 'block', 'civic', 'offici', 'blame', 'combin', 'staff', 'shortag', 'defunct', 'garbag', 'collect', 'truck', 'sorri', 'state', 'affair', 'report', 'work', 'fear', 'contract', 'coronavirus', 'local', 'train', 'run', 'offici', 'say', 'sweeper', 'half', 'number', 'mayor', 'council', 'member', 'jana', 'say', 'worker', 'involv', 'collect', 'garbag', 'sell', 'veget', 'involv', 'activ', 'tri', 'hire', 'personnel', 'pandem', 'come', 'say', 'problem', 'sourc', 'say', 'handcart', 'van', 'break']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzga2tYu48mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e1bc92a9-01a3-4378-c4b4-4b6fa441bcc9"
      },
      "source": [
        "#df['processed_heading'] = df['heading'].map(preprocess)\n",
        "#df['processed_content'] = df['content'].map(preprocess)\n",
        "#df['processed_topic'] = df['topic'].map(preprocess)\n",
        "#df['processed_heading'] = df['processed_heading'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_content'] = df['processed_content'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_topic'] = df['processed_topic'].apply(lambda x: ' '.join(x))\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id  ... processed_topic\n",
              "0  5f04d2481f35ed6864839349  ...     west bengal\n",
              "1  5f04d24b1f35ed686483934a  ...     west bengal\n",
              "2  5f04d24d1f35ed686483934b  ...     west bengal\n",
              "3  5f04d2501f35ed686483934c  ...     west bengal\n",
              "4  5f04d2531f35ed686483934d  ...     west bengal\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfAJav1NLOVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/edited_all_news.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsa-O7Bw48kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from collections import Counter\n",
        "#Counter(df.topic[700:])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBuLrsC3FWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_NewsGroup_data(similarity):    \n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(levelname)s %(message)s')\n",
        "    op = OptionParser()\n",
        "    op.add_option(\"--lsa\", dest=\"n_components\", type=\"int\",\n",
        "                  help=\"Preprocess documents with latent semantic analysis.\")    \n",
        "    op.add_option(\"--no-idf\",action=\"store_false\", dest=\"use_idf\", default=True,\n",
        "                  help=\"Disable Inverse Document Frequency feature weighting.\")\n",
        "    op.add_option(\"--use-hashing\", action=\"store_true\", default=False,\n",
        "                  help=\"Use a hashing feature vectorizer\")\n",
        "    op.add_option(\"--n-features\", type=int, default=10000,\n",
        "                  help=\"Maximum number of features to extract from text.\")    \n",
        "    def is_interactive():\n",
        "        return not hasattr(sys.modules['__main__'], '__file__')\n",
        "    argv = [] if is_interactive() else sys.argv[1:]\n",
        "    (opts, args) = op.parse_args(argv)\n",
        "    if len(args) > 0:\n",
        "        op.error(\"this script takes no arguments.\")\n",
        "        sys.exit(1)\n",
        "        \n",
        "    labels = df.processed_topic[:600]\n",
        "    data = df.processed_content[:600]\n",
        "    #true_k = np.unique(labels).shape[0]\n",
        "    vectorizer = TfidfVectorizer(max_features=opts.n_features,use_idf=opts.use_idf)\n",
        "    X = vectorizer.fit_transform(data)\n",
        "    if opts.n_components:\n",
        "        svd = TruncatedSVD(opts.n_components)\n",
        "        normalizer = Normalizer(copy=False)\n",
        "        lsa = make_pipeline(svd, normalizer)\n",
        "        X = lsa.fit_transform(X)\n",
        "        explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    return Similarity_Dataset_Iterator(X.toarray(), labels, similarity)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZHYkqiV6Gsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Correlation_Similarity as similarity dataset.\n",
        "trainSet_correlation = read_NewsGroup_data(Correlation_Similarity())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZQ9wy646MCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Cosine_Similarity as similarity dataset.\n",
        "trainSet_cosine = read_NewsGroup_data(Cosine_Similarity())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIbetWyC6PMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27f297f8-a240-411f-b1b3-0175b13dc423"
      },
      "source": [
        "n_input = trainSet_correlation.data_size #--------- Number of input data.\n",
        "print(n_input)\n",
        "# Define the number of hidden layer. \n",
        "if n_input >= 1024:\n",
        "    Nn = int(2048)\n",
        "elif n_input >= 512:\n",
        "    Nn = int(1024)\n",
        "elif n_input >= 256:\n",
        "    Nn = int(512)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3m9vsd6X0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden_1 = int(Nn/2) #-------------------- The autoencoder hidden layer 1.\n",
        "n_code = str(int(n_hidden_1/2)) #----------- The number of output dimension value."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeA7y-46cOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0c0e9c8e-7b15-4213-a903-75d1820aa6ef"
      },
      "source": [
        "print('Layer 1: -----------', n_input)\n",
        "print('Layer 2: -----------', n_hidden_1)\n",
        "print('Layer 3: -----------', int(n_code))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1: ----------- 600\n",
            "Layer 2: ----------- 512\n",
            "Layer 3: ----------- 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McRy7WF6gX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means_(X, n_clusters):\n",
        "    kmeans_centroids,_ =  kmeans(X, n_clusters)\n",
        "    kmeans_, _ = vq(X, kmeans_centroids)\n",
        "    return kmeans_"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQwaaHt6nG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, n_code, mode_train):    \n",
        "    with tf.variable_scope(\"encoder\"):        \n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(x, [n_input, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"embedded\"):\n",
        "            code = layer(hidden_1, [n_hidden_1, n_code], [n_code], mode_train)\n",
        "    return code"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9rxQoz6p6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(code, n_code, mode_train):\n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(code, [n_code, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"reconstructed\"):\n",
        "            output = layer(hidden_1, [n_hidden_1, n_input], [n_input], mode_train)\n",
        "    return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8C3fm4r6tdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(x, n_out, mode_train):\n",
        "    beta_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    gamma_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_initialize)\n",
        "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_initialize)\n",
        "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
        "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
        "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
        "    def mean_var():\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
        "    mean, var = control_flow_ops.cond(mode_train, mean_var, lambda: (ema_mean, ema_var))\n",
        "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
        "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-08, True)\n",
        "    return tf.reshape(normed, [-1, n_out])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPomeQMg61f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(input, weight_shape, bias_shape, mode_train):\n",
        "    value_initialize = (1.0 / weight_shape[0] ** 0.5)\n",
        "    weight_initialize = tf.random_normal_initializer(stddev = value_initialize, seed = None)\n",
        "    bias_initialize = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    w = tf.get_variable(\"w\", weight_shape, initializer=weight_initialize)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_initialize)\n",
        "    return tf.nn.sigmoid(batch_norm((tf.matmul(input, w) + b), weight_shape[1], mode_train))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuq5HnwW642G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(reconstructed, x):\n",
        "    with tf.variable_scope(\"train\"):\n",
        "        train_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(reconstructed, x)), 1))\n",
        "        return train_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAIvq9769F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, learning_rate, beta1, beta2, global_step):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIEYZXv7AUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d53825b9-693e-4f22-e6c6-4539f771e7dd"
      },
      "source": [
        "# Parameters\n",
        "n_layers = 3 #------------------------------ Number of Neural Networks Layers.\n",
        "beta1 = 0.9 #------------------------------- The decay rate 1.  \n",
        "beta2 = 0.999 #----------------------------- The decay rate 2.\n",
        "learning_rate = (beta1/n_input) #----------- The learning rate.\n",
        "n_batch = math.ceil(sqrt(sqrt(n_input))) #-- Number of selection data in per step.\n",
        "n_backpro = math.ceil(n_input/n_batch) #---- Number of Backpro in per epoch.\n",
        "n_clusters = 42 #---------------------------- Number of clusters.\n",
        "\n",
        "print(n_batch)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPCpkiff7Kxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cor, labels_cor = trainSet_correlation.whole_dataset() #-- Allocation of data and labels\n",
        "data_cos, labels_cos = trainSet_cosine.whole_dataset() #------- Allocation of data and labels"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5XoVMB7glv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cor=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cor=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cor=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhSKWs97k7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "005f5c65-c572-420d-c6f9-b7114bb4d53f"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_correlation.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "                \n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cor = sess.run(code, feed_dict={x: data_cor, mode_train: False})        \n",
        "    idx_cor = k_means_(ae_codes_cor, n_clusters)\n",
        "    ae_nmi_cor = normalized_mutual_info_score(labels_cor, idx_cor)\n",
        "    ae_nmi_cor = ae_nmi_cor*100\n",
        "    results_cor.append(ae_nmi_cor)    \n",
        "    seeding_cor.append(i)\n",
        "    loss_cost_cor.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cor, new_cost, i))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 49.09 and new cost is: 70.97 in 1 step of seeding.\n",
            "NMI score for AE is: 47.77 and new cost is: 71.79 in 2 step of seeding.\n",
            "NMI score for AE is: 48.53 and new cost is: 71.16 in 3 step of seeding.\n",
            "NMI score for AE is: 50.27 and new cost is: 71.41 in 4 step of seeding.\n",
            "NMI score for AE is: 48.29 and new cost is: 70.89 in 5 step of seeding.\n",
            "NMI score for AE is: 49.00 and new cost is: 71.81 in 6 step of seeding.\n",
            "NMI score for AE is: 48.57 and new cost is: 71.45 in 7 step of seeding.\n",
            "NMI score for AE is: 48.58 and new cost is: 69.97 in 8 step of seeding.\n",
            "NMI score for AE is: 47.95 and new cost is: 70.27 in 9 step of seeding.\n",
            "NMI score for AE is: 48.98 and new cost is: 71.47 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ulspmFn7tu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e516ae0-afa2-4480-b3f9-5a5a8ebb33c2"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Correlation is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cor), (np.mean(results_cor))))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Correlation is >>> 48.70 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1MKJ6iE8Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d9fb6ccf-00ff-4331-b446-ae7066dd2394"
      },
      "source": [
        "results_cor"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49.09079594502077,\n",
              " 47.76795466635927,\n",
              " 48.52626982997213,\n",
              " 50.265246964185714,\n",
              " 48.290659759862294,\n",
              " 49.00309219502035,\n",
              " 48.565879352036546,\n",
              " 48.580144278743354,\n",
              " 47.94534309802756,\n",
              " 48.975771396199356]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXecHj3NE8Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cos=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cos=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cos=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERMUm14E8SQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "df032524-e5fd-41ff-b772-144f704a837a"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_cosine.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "\n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cos = sess.run(code, feed_dict={x: data_cos, mode_train: False})        \n",
        "    idx_cos = k_means_(ae_codes_cos, n_clusters)\n",
        "    ae_nmi_cos = normalized_mutual_info_score(labels_cos, idx_cos)\n",
        "    ae_nmi_cos = ae_nmi_cos*100\n",
        "    results_cos.append(ae_nmi_cos)    \n",
        "    seeding_cos.append(i)\n",
        "    loss_cost_cos.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cos, new_cost, i))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 48.50 and new cost is: 72.04 in 1 step of seeding.\n",
            "NMI score for AE is: 48.73 and new cost is: 72.21 in 2 step of seeding.\n",
            "NMI score for AE is: 49.76 and new cost is: 72.03 in 3 step of seeding.\n",
            "NMI score for AE is: 50.34 and new cost is: 72.81 in 4 step of seeding.\n",
            "NMI score for AE is: 49.25 and new cost is: 72.28 in 5 step of seeding.\n",
            "NMI score for AE is: 48.47 and new cost is: 72.30 in 6 step of seeding.\n",
            "NMI score for AE is: 48.57 and new cost is: 72.33 in 7 step of seeding.\n",
            "NMI score for AE is: 49.24 and new cost is: 72.08 in 8 step of seeding.\n",
            "NMI score for AE is: 48.73 and new cost is: 72.43 in 9 step of seeding.\n",
            "NMI score for AE is: 48.97 and new cost is: 71.94 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL6sjMQEFIXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70fa3caa-588f-4aa4-9b80-49332ecfb50d"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Cosine is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cos), (np.mean(results_cos))))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Cosine is >>> 49.06 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQmt5pjFIa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ad4fbd1a-9aa3-4f1d-e41b-bb36be486ea7"
      },
      "source": [
        "results_cos"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48.49758236985576,\n",
              " 48.73355459837846,\n",
              " 49.75985408325067,\n",
              " 50.34440521041201,\n",
              " 49.24974690796446,\n",
              " 48.47354167901624,\n",
              " 48.57471418302009,\n",
              " 49.24271772750068,\n",
              " 48.72610828542981,\n",
              " 48.96775865749791]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3afCnSOFIVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7b6dd6b7-14de-4321-b529-3732edfb6046"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "plt.ylim(30,101)\n",
        "plt.plot(seeding_cor, results_cor, label='Autoencoder Correlation Simialrity', color='m', marker='o')\n",
        "plt.plot(seeding_cos, results_cos, label='Autoencoder Cosine Simialrity', color='g', marker='s')\n",
        "plt.xlabel('Number of Seeding.')\n",
        "plt.ylabel('NMI')\n",
        "plt.grid()\n",
        "plt.title('The Average of NMI Scores')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIhu5zg4FeA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4aaf6075-67ae-4896-9e4f-f8702e5e4c7b"
      },
      "source": [
        "print(\"Autoencoder Clustering on Cosine: ------------ {:0.2f}\".format(np.mean(results_cos)))\n",
        "print(\"Autoencoder Clustering on Correlation: ------- {:0.2f}\".format(np.mean(results_cor)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder Clustering on Cosine: ------------ 49.06\n",
            "Autoencoder Clustering on Correlation: ------- 48.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uGhkhbeRmFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}