{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-NN_clustering_set2_awesome.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mxZOMIDXXau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import math\n",
        "import sys\n",
        "import logging\n",
        "#-----------------------------------------------------------\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from IPython.display import clear_output\n",
        "from scipy.spatial.distance import squareform, pdist\n",
        "from sklearn.preprocessing import normalize\n",
        "from numpy import linalg as LA\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from math import sqrt\n",
        "#----------------------------------------------\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from optparse import OptionParser\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqX8ZR5wsGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardization(X):\n",
        "    return normalize(X, axis=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKho_sESzQMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laplacian(A):\n",
        "    S = np.sum(A, 0)\n",
        "    D = np.diag(S)\n",
        "    D = LA.matrix_power(D, -1)\n",
        "    L = np.dot(D, A)\n",
        "    return L"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUSpsQozS-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization(V):\n",
        "    return (V - min(V)) / (max(V) - min(V))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndbmGyJzWIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Correlation_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'correlation')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHrGqwRnzY-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cosine_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'cosine')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV0iHGWzcp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Similarity_Dataset_Iterator():\n",
        "    def __init__(self, data, labels, similarity):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.matrix = similarity.get_matrix(data)\n",
        "        self.data_size = self.matrix.shape[0]\n",
        "        self.current_index = 0\n",
        "    def next_batch(self, num):\n",
        "        data=self.matrix.transpose()\n",
        "        labels=self.labels\n",
        "        idx = np.arange(0 , len(data))\n",
        "        np.random.shuffle(idx)\n",
        "        idx = idx[:num]\n",
        "        data_shuffle = [data[ i] for i in idx]\n",
        "        labels_shuffle = [labels[ i] for i in idx]\n",
        "        return data_shuffle, labels_shuffle\n",
        "    def whole_dataset(self):\n",
        "        return (self.matrix.transpose(), self.labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n076atQh0kmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3U9x9aT05Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e31f7b76-ef52-480d-c774-2c6132afa1c2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/edited_topics_set2.csv')\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>content</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5f04e496ef217aae6a201f71</td>\n",
              "      <td>[\"National\"]</td>\n",
              "      <td>[\"The West Bengal government on Tuesday decide...</td>\n",
              "      <td>west bengal govern tuesday decid impos complet...</td>\n",
              "      <td>nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5f04e498ef217aae6a201f72</td>\n",
              "      <td>[\"Business\"]</td>\n",
              "      <td>[\"The government is weighing the pros and cons...</td>\n",
              "      <td>govern weigh pros con halt import includ china...</td>\n",
              "      <td>busi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5f04e49aef217aae6a201f73</td>\n",
              "      <td>[\"National\"]</td>\n",
              "      <td>[\"The Central Board of Secondary Education (CB...</td>\n",
              "      <td>central board secondari educ cbse slash syllab...</td>\n",
              "      <td>nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5f04e49def217aae6a201f74</td>\n",
              "      <td>[\"International\"]</td>\n",
              "      <td>[\"The World Health Organization on Tuesday ack...</td>\n",
              "      <td>world health organ tuesday acknowledg emerg ev...</td>\n",
              "      <td>intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5f04e49fef217aae6a201f75</td>\n",
              "      <td>[\"International\"]</td>\n",
              "      <td>[\"President Donald Trump on Tuesday formally s...</td>\n",
              "      <td>presid donald trump tuesday formal start withd...</td>\n",
              "      <td>intern</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  processed_topic\n",
              "0           0  ...           nation\n",
              "1           1  ...             busi\n",
              "2           2  ...           nation\n",
              "3           3  ...           intern\n",
              "4           4  ...           intern\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUhy5jVOp6N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "660d82d6-ff68-4644-a0af-c06314266f26"
      },
      "source": [
        "df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>content</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f04e496ef217aae6a201f71</td>\n",
              "      <td>[\"National\"]</td>\n",
              "      <td>[\"The West Bengal government on Tuesday decide...</td>\n",
              "      <td>west bengal govern tuesday decid impos complet...</td>\n",
              "      <td>nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5f04e498ef217aae6a201f72</td>\n",
              "      <td>[\"Business\"]</td>\n",
              "      <td>[\"The government is weighing the pros and cons...</td>\n",
              "      <td>govern weigh pros con halt import includ china...</td>\n",
              "      <td>busi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5f04e49aef217aae6a201f73</td>\n",
              "      <td>[\"National\"]</td>\n",
              "      <td>[\"The Central Board of Secondary Education (CB...</td>\n",
              "      <td>central board secondari educ cbse slash syllab...</td>\n",
              "      <td>nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f04e49def217aae6a201f74</td>\n",
              "      <td>[\"International\"]</td>\n",
              "      <td>[\"The World Health Organization on Tuesday ack...</td>\n",
              "      <td>world health organ tuesday acknowledg emerg ev...</td>\n",
              "      <td>intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5f04e49fef217aae6a201f75</td>\n",
              "      <td>[\"International\"]</td>\n",
              "      <td>[\"President Donald Trump on Tuesday formally s...</td>\n",
              "      <td>presid donald trump tuesday formal start withd...</td>\n",
              "      <td>intern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>5f04c5bd2ba198f21c82c4b2</td>\n",
              "      <td>[\"Business\"]</td>\n",
              "      <td>[\"Ride-hailing platform Ola on Tuesday announc...</td>\n",
              "      <td>ride hail platform tuesday announc enter strat...</td>\n",
              "      <td>busi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>5f04c5c02ba198f21c82c4b3</td>\n",
              "      <td>[\"Coronavirus\"]</td>\n",
              "      <td>[\"Delhi Chief Minister Arvind Kejriwal on Mond...</td>\n",
              "      <td>delhi chief minist arvind kejriw monday appeal...</td>\n",
              "      <td>coronavirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>5f04c5c22ba198f21c82c4b4</td>\n",
              "      <td>[\"Cities\"]</td>\n",
              "      <td>[\"Tibetan spiritual leader Dalai Lama on Monda...</td>\n",
              "      <td>tibetan spiritu leader dalai lama monday celeb...</td>\n",
              "      <td>citi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>5f04c5c42ba198f21c82c4b5</td>\n",
              "      <td>[\"Business\"]</td>\n",
              "      <td>[\"Infosys has brought back a little more than ...</td>\n",
              "      <td>infosi bring littl peopl primarili includ comp...</td>\n",
              "      <td>busi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2154</th>\n",
              "      <td>5f04c5c82ba198f21c82c4b6</td>\n",
              "      <td>[\"Business\"]</td>\n",
              "      <td>[\"India’s largest carmaker Maruti Suzuki on Tu...</td>\n",
              "      <td>india largest carmak maruti suzuki tuesday ann...</td>\n",
              "      <td>busi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2155 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           _id  ... processed_topic\n",
              "0     5f04e496ef217aae6a201f71  ...          nation\n",
              "1     5f04e498ef217aae6a201f72  ...            busi\n",
              "2     5f04e49aef217aae6a201f73  ...          nation\n",
              "3     5f04e49def217aae6a201f74  ...          intern\n",
              "4     5f04e49fef217aae6a201f75  ...          intern\n",
              "...                        ...  ...             ...\n",
              "2150  5f04c5bd2ba198f21c82c4b2  ...            busi\n",
              "2151  5f04c5c02ba198f21c82c4b3  ...     coronavirus\n",
              "2152  5f04c5c22ba198f21c82c4b4  ...            citi\n",
              "2153  5f04c5c42ba198f21c82c4b5  ...            busi\n",
              "2154  5f04c5c82ba198f21c82c4b6  ...            busi\n",
              "\n",
              "[2155 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0GlS3WC1Udh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.dropna(subset=['content'], inplace = True)\n",
        "df.dropna(subset=['processed_topic'], inplace = True)\n",
        "#df['your column name'].isnull().values.any()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dat6uH3E2OmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cced1ae-d391-4f6d-f054-a8e03a90c9ed"
      },
      "source": [
        "#len(df.content.unique()),  len(df.content), len(df.topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1204, 1304, 1304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S87soJgE2SZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "833dba4c-6c3b-4390-e27f-d624764c4c18"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0           0\n",
              "Unnamed: 0.1         0\n",
              "_id                  0\n",
              "topic                0\n",
              "content              0\n",
              "processed_content    0\n",
              "processed_topic      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PbPTbyu2deC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dba2b6f-40a8-4aa6-e07b-ddaed8d657e7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2155, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0qrfJGtSkVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d982739c-8951-4e81-96f8-ef64e1d477a7"
      },
      "source": [
        "np.unique(df.processed_topic[:600]).shape[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-XKjCAS48pD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3ad50f97-3371-499a-d3ab-f8d4bcf72e1f"
      },
      "source": [
        "#import re\n",
        "\n",
        "#import gensim\n",
        "#from gensim import corpora,models\n",
        "#from gensim.utils import simple_preprocess\n",
        "#from gensim.models import CoherenceModel\n",
        "#from gensim.parsing.preprocessing import STOPWORDS\n",
        "#from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "#from nltk.stem.porter import *\n",
        "#import numpy as np\n",
        "#np.random.seed(2018)\n",
        "\n",
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2dezj2a48qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemmer = SnowballStemmer(language='english',ignore_stopwords=True)\n",
        "#def lemmatize_stemming(text):\n",
        "#    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "#def preprocess(text):\n",
        "    #result = []\n",
        "   # for token in gensim.utils.simple_preprocess(text):\n",
        "   #     if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "   #         result.append(lemmatize_stemming(token))\n",
        "  #  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws57P9WE48uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "3eb64829-6726-4133-b90f-7e0f43b0be4e"
      },
      "source": [
        "#doc_sample = df['content'][0]\n",
        "#print('original document: ')\n",
        "#words = []\n",
        "#for word in doc_sample.split(' '):\n",
        "#    words.append(word)\n",
        "#print(words)\n",
        "#print('\\n\\n tokenized and lemmatized document: ')\n",
        "#print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['[\"Garbage-lined', 'streets', 'and', 'overflowing', 'drains', 'across', 'Salt', 'Lake', 'have', 'sparked', 'fear', 'of', 'an', 'outbreak', 'of', 'enteric', 'diseases', 'and', 'are', 'forcing', 'residents', 'to', 'keep', 'the', 'windows', 'and', 'doors', 'of', 'their', 'houses', 'firmly', 'shut.\",\"Residents', 'said', 'most', 'of', 'the', '150', 'tonnes', 'of', 'the', 'garbage', 'Salt', 'Lake', 'generates', 'every', 'day', 'is', 'accumulating', 'across', 'the', '33.5sq', 'km', 'township.\",\"“At', 'this', 'rate,', 'Salt', 'Lake', 'will', 'soon', 'become', 'Dhapa.', 'This', 'is', 'happening', 'at', 'a', 'time', 'the', 'authorities', 'as', 'well', 'as', 'residents', 'need', 'to', 'focus', 'on', 'hygiene', 'to', 'combat', 'Covid', 'and', 'dengue,”', 'said', 'a', 'resident,', 'hand', 'firmly', 'on', 'his', 'nose.\",\"“It', 'is', 'true', 'that', 'garbage', 'has', 'accumulated', 'in', 'some', 'places', 'but', 'I', 'don’t', 'think', 'it', 'is', 'a', 'big', 'problem.', 'We', 'will', 'clear', 'it', 'within', 'seven', 'days,”', 'said', 'Debasish', 'Jana,', 'the', 'mayoral', 'council', 'member', 'in', 'charge', 'of', 'solid', 'waste', 'management', 'at', 'the', 'Bidhannagar', 'Municipal', 'Corporation.\",\"Asked', 'why', 'the', 'civic', 'body', 'has', 'not', 'yet', 'been', 'able', 'to', 'solve', 'a', '“simple', 'problem”,', 'Jana', 'said:', '“Several', 'of', 'our', 'trucks', 'are', 'out', 'of', 'order,', 'but', 'our', 'sweepers', 'are', 'at', 'work', 'all', 'day.', 'It’s', 'just', 'that', 'accumulated', 'garbage', 'isn’t', 'being', 'removed', 'regularly', 'from', 'a', 'few', 'areas.”\",\"For', 'five', 'days', 'a', 'week,', 'Buddhadeb', 'Basu,', 'a', 'resident', 'of', 'DB', 'block,', 'near', 'City', 'Centre,', 'is', 'having', 'to', 'dump', 'household', 'waste', 'at', 'the', 'neighbourhood', 'compactor', 'station', 'overflowing', 'with', 'garbage.', 'He', 'doesn’t', 'have', 'a', 'choice.', 'His', 'neighbours,', 'too,', 'are', 'doing', 'the', 'same.\",\"“Civic', 'workers', 'would', 'previously', 'collect', 'garbage', 'from', 'our', 'doorstep', 'every', 'day.', 'Now', 'they', 'come', 'hardly', 'twice', 'a', 'week.', 'They', 'are', 'not', 'even', 'taking', 'away', 'garbage', 'from', 'near', 'the', 'compactor', 'station.', 'The', 'entire', 'area', 'stinks,”', 'the', '62-year-old', 'told', '\",\"The', 'Telegraph\",\".\",\"This', 'newspaper', 'drove', 'around', 'the', 'township', 'on', 'Monday', 'and', 'found', 'scarcely', 'any', 'block', 'or', 'compactor', 'station', 'that', 'did', 'not', 'have', 'a', 'heap', 'of', 'garbage', 'lying', 'around.\",\"The', 'areas', 'near', 'City', 'Centre', 'and', 'the', 'CGO', 'Complex', 'looked', 'the', 'dirtiest.', 'The', 'situation', 'was', 'similar', 'in', 'the', 'AE,', 'AB,', 'BC,', 'BB,', 'and', 'IC', 'blocks.\",\"A', '20-metre', 'stretch', 'from', 'the', 'City', 'Centre', 'Metro', 'station', 'till', 'Bidhannagar', 'College', 'had', 'almost', 'half', 'the', 'carriageway', 'swallowed', 'by', 'garbage.', 'The', 'entire', 'area', 'had', 'flies', 'swarming', 'around,', 'while', 'several', 'dogs', 'and', 'cows', 'were', 'seen', 'rummaging', 'through', 'the', 'garbage', 'for', 'food.\",\"Passers-by', 'were', 'seen', 'holding', 'handkerchiefs', 'on', 'their', 'noses', 'despite', 'wearing', 'masks.\",\"“The', 'stench', 'from', 'the', 'garbage', 'in', 'front', 'of', 'our', 'house', 'is', 'so', 'overpowering', 'that', 'we', 'keep', 'the', 'windows', 'of', 'our', 'house', 'shut,”', 'said', 'Prakash', 'Agarwal,', 'a', 'resident', 'of', 'EC', 'Block.\",\"A', 'civic', 'official', 'blamed', 'the', 'combination', 'of', 'staff', 'shortage', 'and', 'defunct', 'garbage', 'collection', 'trucks', 'for', 'the', 'sorry', 'state', 'of', 'affairs.\\xa0', '“Many', 'men', 'are', 'not', 'reporting', 'for', 'work', 'out', 'of', 'fear', 'of', 'contracting', 'the', 'coronavirus', 'and', 'also', 'because', 'local', 'trains', 'are', 'not', 'running,”', 'the', 'official', 'said.', '“There', 'used', 'to', 'be', '250', 'sweepers.', 'Now,', 'there', 'are', 'only', 'half', 'that\\xa0number.”\",\"Mayoral', 'council', 'member', 'Jana', 'said', 'many', 'workers', 'who', 'were', 'involved', 'in', 'collection', 'of', 'garbage', 'were', 'now', 'selling', 'vegetables', 'or', 'involved', 'in', 'other', 'activities.', '“We', 'are', 'trying', 'to', 'hire', 'personnel', 'but', 'the', 'pandemic', 'is', 'coming', 'in', 'the', 'way,”', 'he', 'said.\",\"To', 'add', 'to', 'the', 'problem,', 'sources', 'said,', 'many', 'handcarts', 'and', 'vans', 'have', 'broken', 'down.\"]']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['garbag', 'line', 'street', 'overflow', 'drain', 'salt', 'lake', 'spark', 'fear', 'outbreak', 'enter', 'diseas', 'forc', 'resid', 'window', 'door', 'hous', 'firm', 'shut', 'resid', 'say', 'tonn', 'garbag', 'salt', 'lake', 'generat', 'accumul', 'township', 'rate', 'salt', 'lake', 'soon', 'dhapa', 'happen', 'time', 'author', 'resid', 'need', 'focus', 'hygien', 'combat', 'covid', 'dengu', 'say', 'resid', 'hand', 'firm', 'nose', 'true', 'garbag', 'accumul', 'place', 'think', 'problem', 'clear', 'seven', 'day', 'say', 'debasish', 'jana', 'mayor', 'council', 'member', 'charg', 'solid', 'wast', 'manag', 'bidhannagar', 'municip', 'corpor', 'ask', 'civic', 'bodi', 'abl', 'solv', 'simpl', 'problem', 'jana', 'say', 'truck', 'order', 'sweeper', 'work', 'accumul', 'garbag', 'remov', 'regular', 'area', 'day', 'week', 'buddhadeb', 'basu', 'resid', 'block', 'near', 'citi', 'centr', 'have', 'dump', 'household', 'wast', 'neighbourhood', 'compactor', 'station', 'overflow', 'garbag', 'choic', 'neighbour', 'civic', 'worker', 'previous', 'collect', 'garbag', 'doorstep', 'come', 'hard', 'twice', 'week', 'take', 'away', 'garbag', 'near', 'compactor', 'station', 'entir', 'area', 'stink', 'year', 'tell', 'telegraph', 'newspap', 'drive', 'township', 'monday', 'scarc', 'block', 'compactor', 'station', 'heap', 'garbag', 'lie', 'area', 'near', 'citi', 'centr', 'complex', 'look', 'dirtiest', 'situat', 'similar', 'block', 'metr', 'stretch', 'citi', 'centr', 'metro', 'station', 'till', 'bidhannagar', 'colleg', 'half', 'carriageway', 'swallow', 'garbag', 'entir', 'area', 'fli', 'swarm', 'dog', 'cow', 'see', 'rummag', 'garbag', 'food', 'passer', 'see', 'hold', 'handkerchief', 'nose', 'despit', 'wear', 'mask', 'stench', 'garbag', 'hous', 'overpow', 'window', 'hous', 'shut', 'say', 'prakash', 'agarw', 'resid', 'block', 'civic', 'offici', 'blame', 'combin', 'staff', 'shortag', 'defunct', 'garbag', 'collect', 'truck', 'sorri', 'state', 'affair', 'report', 'work', 'fear', 'contract', 'coronavirus', 'local', 'train', 'run', 'offici', 'say', 'sweeper', 'half', 'number', 'mayor', 'council', 'member', 'jana', 'say', 'worker', 'involv', 'collect', 'garbag', 'sell', 'veget', 'involv', 'activ', 'tri', 'hire', 'personnel', 'pandem', 'come', 'say', 'problem', 'sourc', 'say', 'handcart', 'van', 'break']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzga2tYu48mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e1bc92a9-01a3-4378-c4b4-4b6fa441bcc9"
      },
      "source": [
        "#df['processed_heading'] = df['heading'].map(preprocess)\n",
        "#df['processed_content'] = df['content'].map(preprocess)\n",
        "#df['processed_topic'] = df['topic'].map(preprocess)\n",
        "#df['processed_heading'] = df['processed_heading'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_content'] = df['processed_content'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_topic'] = df['processed_topic'].apply(lambda x: ' '.join(x))\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id  ... processed_topic\n",
              "0  5f04d2481f35ed6864839349  ...     west bengal\n",
              "1  5f04d24b1f35ed686483934a  ...     west bengal\n",
              "2  5f04d24d1f35ed686483934b  ...     west bengal\n",
              "3  5f04d2501f35ed686483934c  ...     west bengal\n",
              "4  5f04d2531f35ed686483934d  ...     west bengal\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfAJav1NLOVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/edited_all_news.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsa-O7Bw48kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from collections import Counter\n",
        "#Counter(df.topic[700:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBuLrsC3FWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_NewsGroup_data(similarity):    \n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(levelname)s %(message)s')\n",
        "    op = OptionParser()\n",
        "    op.add_option(\"--lsa\", dest=\"n_components\", type=\"int\",\n",
        "                  help=\"Preprocess documents with latent semantic analysis.\")    \n",
        "    op.add_option(\"--no-idf\",action=\"store_false\", dest=\"use_idf\", default=True,\n",
        "                  help=\"Disable Inverse Document Frequency feature weighting.\")\n",
        "    op.add_option(\"--use-hashing\", action=\"store_true\", default=False,\n",
        "                  help=\"Use a hashing feature vectorizer\")\n",
        "    op.add_option(\"--n-features\", type=int, default=10000,\n",
        "                  help=\"Maximum number of features to extract from text.\")    \n",
        "    def is_interactive():\n",
        "        return not hasattr(sys.modules['__main__'], '__file__')\n",
        "    argv = [] if is_interactive() else sys.argv[1:]\n",
        "    (opts, args) = op.parse_args(argv)\n",
        "    if len(args) > 0:\n",
        "        op.error(\"this script takes no arguments.\")\n",
        "        sys.exit(1)\n",
        "        \n",
        "    labels = df.processed_topic\n",
        "    data = df.processed_content\n",
        "        #true_k = np.unique(labels).shape[0]\n",
        "    vectorizer = TfidfVectorizer(max_features=opts.n_features,use_idf=opts.use_idf)\n",
        "    X = vectorizer.fit_transform(data)\n",
        "    if opts.n_components:\n",
        "        svd = TruncatedSVD(opts.n_components)\n",
        "        normalizer = Normalizer(copy=False)\n",
        "        lsa = make_pipeline(svd, normalizer)\n",
        "        X = lsa.fit_transform(X)\n",
        "        explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    return Similarity_Dataset_Iterator(X.toarray(), labels, similarity)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZHYkqiV6Gsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Correlation_Similarity as similarity dataset.\n",
        "trainSet_correlation = read_NewsGroup_data(Correlation_Similarity())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZQ9wy646MCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Cosine_Similarity as similarity dataset.\n",
        "trainSet_cosine = read_NewsGroup_data(Cosine_Similarity())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIbetWyC6PMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23b5001b-eaef-4eaa-d3cc-3a7ccce8959b"
      },
      "source": [
        "n_input = trainSet_correlation.data_size #--------- Number of input data.\n",
        "print(n_input)\n",
        "# Define the number of hidden layer. \n",
        "if n_input >= 1024:\n",
        "    Nn = int(2048)\n",
        "elif n_input >= 512:\n",
        "    Nn = int(1024)\n",
        "elif n_input >= 256:\n",
        "    Nn = int(512)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3m9vsd6X0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden_1 = int(Nn/2) #-------------------- The autoencoder hidden layer 1.\n",
        "n_code = str(int(n_hidden_1/2)) #----------- The number of output dimension value."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeA7y-46cOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a81f5e32-0f27-48fe-8383-cd8c05245b9e"
      },
      "source": [
        "print('Layer 1: -----------', n_input)\n",
        "print('Layer 2: -----------', n_hidden_1)\n",
        "print('Layer 3: -----------', int(n_code))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1: ----------- 2155\n",
            "Layer 2: ----------- 1024\n",
            "Layer 3: ----------- 512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McRy7WF6gX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means_(X, n_clusters):\n",
        "    kmeans_centroids,_ =  kmeans(X, n_clusters)\n",
        "    kmeans_, _ = vq(X, kmeans_centroids)\n",
        "    return kmeans_"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQwaaHt6nG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, n_code, mode_train):    \n",
        "    with tf.variable_scope(\"encoder\"):        \n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(x, [n_input, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"embedded\"):\n",
        "            code = layer(hidden_1, [n_hidden_1, n_code], [n_code], mode_train)\n",
        "    return code"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9rxQoz6p6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(code, n_code, mode_train):\n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(code, [n_code, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"reconstructed\"):\n",
        "            output = layer(hidden_1, [n_hidden_1, n_input], [n_input], mode_train)\n",
        "    return output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8C3fm4r6tdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(x, n_out, mode_train):\n",
        "    beta_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    gamma_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_initialize)\n",
        "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_initialize)\n",
        "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
        "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
        "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
        "    def mean_var():\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
        "    mean, var = control_flow_ops.cond(mode_train, mean_var, lambda: (ema_mean, ema_var))\n",
        "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
        "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-08, True)\n",
        "    return tf.reshape(normed, [-1, n_out])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPomeQMg61f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(input, weight_shape, bias_shape, mode_train):\n",
        "    value_initialize = (1.0 / weight_shape[0] ** 0.5)\n",
        "    weight_initialize = tf.random_normal_initializer(stddev = value_initialize, seed = None)\n",
        "    bias_initialize = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    w = tf.get_variable(\"w\", weight_shape, initializer=weight_initialize)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_initialize)\n",
        "    return tf.nn.sigmoid(batch_norm((tf.matmul(input, w) + b), weight_shape[1], mode_train))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuq5HnwW642G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(reconstructed, x):\n",
        "    with tf.variable_scope(\"train\"):\n",
        "        train_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(reconstructed, x)), 1))\n",
        "        return train_loss"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAIvq9769F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, learning_rate, beta1, beta2, global_step):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIEYZXv7AUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e63b3f6-d5a3-4643-e5fa-0a22a2157e43"
      },
      "source": [
        "# Parameters\n",
        "n_layers = 3 #------------------------------ Number of Neural Networks Layers.\n",
        "beta1 = 0.9 #------------------------------- The decay rate 1.  \n",
        "beta2 = 0.999 #----------------------------- The decay rate 2.\n",
        "learning_rate = (beta1/n_input) #----------- The learning rate.\n",
        "#n_batch = math.ceil(sqrt(sqrt(n_input))) #-- Number of selection data in per step.\n",
        "n_batch = 32\n",
        "n_backpro = math.ceil(n_input/n_batch) #---- Number of Backpro in per epoch.\n",
        "n_clusters = 20 #---------------------------- Number of clusters.\n",
        "\n",
        "print(n_batch)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPCpkiff7Kxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cor, labels_cor = trainSet_correlation.whole_dataset() #-- Allocation of data and labels\n",
        "data_cos, labels_cos = trainSet_cosine.whole_dataset() #------- Allocation of data and labels"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5XoVMB7glv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cor=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cor=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cor=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhSKWs97k7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6f8fa173-a875-4432-c3d1-ad37702cb662"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_correlation.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "                \n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cor = sess.run(code, feed_dict={x: data_cor, mode_train: False})        \n",
        "    idx_cor = k_means_(ae_codes_cor, n_clusters)\n",
        "    ae_nmi_cor = normalized_mutual_info_score(labels_cor, idx_cor)\n",
        "    ae_nmi_cor = ae_nmi_cor*100\n",
        "    results_cor.append(ae_nmi_cor)    \n",
        "    seeding_cor.append(i)\n",
        "    loss_cost_cor.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cor, new_cost, i))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 37.68 and new cost is: 422.54 in 1 step of seeding.\n",
            "NMI score for AE is: 37.51 and new cost is: 420.15 in 2 step of seeding.\n",
            "NMI score for AE is: 36.51 and new cost is: 421.10 in 3 step of seeding.\n",
            "NMI score for AE is: 37.32 and new cost is: 421.14 in 4 step of seeding.\n",
            "NMI score for AE is: 35.62 and new cost is: 421.02 in 5 step of seeding.\n",
            "NMI score for AE is: 36.51 and new cost is: 422.43 in 6 step of seeding.\n",
            "NMI score for AE is: 36.77 and new cost is: 421.51 in 7 step of seeding.\n",
            "NMI score for AE is: 38.98 and new cost is: 420.52 in 8 step of seeding.\n",
            "NMI score for AE is: 37.65 and new cost is: 421.19 in 9 step of seeding.\n",
            "NMI score for AE is: 37.62 and new cost is: 422.22 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ulspmFn7tu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00ce19b7-768c-4a09-b788-a5e230e909a0"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Correlation is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cor), (np.mean(results_cor))))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Correlation is >>> 37.22 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1MKJ6iE8Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9902dda0-1c60-474e-c020-c2bcc30ca190"
      },
      "source": [
        "results_cor"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37.68267198140483,\n",
              " 37.513186163571646,\n",
              " 36.506454161644456,\n",
              " 37.31853951214437,\n",
              " 35.620455271752775,\n",
              " 36.509509537851734,\n",
              " 36.77475349357957,\n",
              " 38.98128846698066,\n",
              " 37.654179927192985,\n",
              " 37.620620540399315]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXecHj3NE8Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cos=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cos=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cos=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERMUm14E8SQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "100c8316-0eb0-4ccc-fcca-34c7a94c2e1d"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_cosine.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "\n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cos = sess.run(code, feed_dict={x: data_cos, mode_train: False})        \n",
        "    idx_cos = k_means_(ae_codes_cos, n_clusters)\n",
        "    ae_nmi_cos = normalized_mutual_info_score(labels_cos, idx_cos)\n",
        "    ae_nmi_cos = ae_nmi_cos*100\n",
        "    results_cos.append(ae_nmi_cos)    \n",
        "    seeding_cos.append(i)\n",
        "    loss_cost_cos.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cos, new_cost, i))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 34.60 and new cost is: 426.64 in 1 step of seeding.\n",
            "NMI score for AE is: 35.53 and new cost is: 424.53 in 2 step of seeding.\n",
            "NMI score for AE is: 37.36 and new cost is: 424.68 in 3 step of seeding.\n",
            "NMI score for AE is: 36.78 and new cost is: 426.82 in 4 step of seeding.\n",
            "NMI score for AE is: 36.29 and new cost is: 424.57 in 5 step of seeding.\n",
            "NMI score for AE is: 35.38 and new cost is: 424.83 in 6 step of seeding.\n",
            "NMI score for AE is: 38.41 and new cost is: 426.83 in 7 step of seeding.\n",
            "NMI score for AE is: 38.16 and new cost is: 425.14 in 8 step of seeding.\n",
            "NMI score for AE is: 39.37 and new cost is: 426.41 in 9 step of seeding.\n",
            "NMI score for AE is: 38.56 and new cost is: 424.41 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL6sjMQEFIXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5e27f33-edd6-4e32-b66d-63ab41ab591f"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Cosine is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cos), (np.mean(results_cos))))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Cosine is >>> 37.04 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQmt5pjFIa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "3b960e47-240a-4d79-ed07-e512ea3729bc"
      },
      "source": [
        "results_cos"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34.600464951696985,\n",
              " 35.53200700308353,\n",
              " 37.36117612917431,\n",
              " 36.77599636756918,\n",
              " 36.28834205297791,\n",
              " 35.37993052038826,\n",
              " 38.40736878877157,\n",
              " 38.16090629093182,\n",
              " 39.36749434228251,\n",
              " 38.558287418052664]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3afCnSOFIVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "42d5a511-9000-432a-b9e3-3d1cbf8d4a5a"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "plt.ylim(30,101)\n",
        "plt.plot(seeding_cor, results_cor, label='Autoencoder Correlation Simialrity', color='m', marker='o')\n",
        "plt.plot(seeding_cos, results_cos, label='Autoencoder Cosine Simialrity', color='g', marker='s')\n",
        "plt.xlabel('Number of Seeding.')\n",
        "plt.ylabel('NMI')\n",
        "plt.grid()\n",
        "plt.title('The Average of NMI Scores')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIhu5zg4FeA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "02409208-76f0-48c8-c31b-ee28cfc252cd"
      },
      "source": [
        "print(\"Autoencoder Clustering on Cosine: ------------ {:0.2f}\".format(np.mean(results_cos)))\n",
        "print(\"Autoencoder Clustering on Correlation: ------- {:0.2f}\".format(np.mean(results_cor)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder Clustering on Cosine: ------------ 37.04\n",
            "Autoencoder Clustering on Correlation: ------- 37.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixX7LbI8vkFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uGhkhbeRmFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature extraction\n",
        "vec = TfidfVectorizer(stop_words=\"english\")\n",
        "vec.fit(df.processed_content.values)\n",
        "features = vec.transform(df.processed_content.values)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8TxX5SnyIUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "426bf94e-148d-45df-a36b-3c2405d776e7"
      },
      "source": [
        "# function to print out classification model report\n",
        "def classification_report(model_name, test, pred):\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    \n",
        "    print(model_name, \":\\n\")\n",
        "    print(\"Accuracy Score: \", '{:,.3f}'.format(float(accuracy_score(test, pred)) * 100), \"%\")\n",
        "    print(\"     Precision: \", '{:,.3f}'.format(float(precision_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    print(\"        Recall: \", '{:,.3f}'.format(float(recall_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    print(\"      F1 score: \", '{:,.3f}'.format(float(f1_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    \n",
        "#Let's split the data into train/test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test set size of 20% of the data and the random seed 42 <3\n",
        "X_train, X_test, y_train, y_test = train_test_split(features.toarray(),idx_cor, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train size:\", len(X_train))\n",
        "print(\"X_test size:\", len(X_test), \"\\n\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train size: 1724\n",
            "X_test size: 431 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdb4tNMw-Dfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "bf6bd888-e8f4-4e08-cfb5-85ae5e4e8923"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# SGD instance\n",
        "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3, random_state=42, n_jobs=4)\n",
        "# train SGD\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "\n",
        "# cross validation predictions\n",
        "sgd_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3, n_jobs=4)\n",
        "\n",
        "# print out the classification report\n",
        "classification_report(\"Stochastic Gradient Descent Report (Training Set)\", y_train, sgd_pred)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stochastic Gradient Descent Report (Training Set) :\n",
            "\n",
            "Accuracy Score:  81.961 %\n",
            "     Precision:  87.106 %\n",
            "        Recall:  83.483 %\n",
            "      F1 score:  84.651 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLkx3Y3h-Gnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "72c097aa-795d-47da-f84c-3b375562436a"
      },
      "source": [
        "# cross validation predictions\n",
        "sgd_pred = cross_val_predict(sgd_clf, X_test, y_test, cv=3, n_jobs=4)\n",
        "\n",
        "# print out the classification report\n",
        "classification_report(\"Stochastic Gradient Descent Report (Training Set)\", y_test, sgd_pred)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stochastic Gradient Descent Report (Training Set) :\n",
            "\n",
            "Accuracy Score:  72.158 %\n",
            "     Precision:  76.115 %\n",
            "        Recall:  71.924 %\n",
            "      F1 score:  72.476 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auQchy8U-JJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0dffb73-5cb3-475c-faef-8af810546e0c"
      },
      "source": [
        "sgd_cv_score = cross_val_score(sgd_clf, features.toarray(), idx_cor, cv=10)\n",
        "print(\"Mean cv Score - SGD: {:,.3f}\".format(float(sgd_cv_score.mean()) * 100), \"%\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv Score - SGD: 82.691 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbvYI5MvwnZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP805FdoxzyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U27qa1VAx0Gz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c31b5c0f-a421-4810-979f-61960173ebf6"
      },
      "source": [
        "# function to print out classification model report\n",
        "def classification_report(model_name, test, pred):\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    \n",
        "    print(model_name, \":\\n\")\n",
        "    print(\"Accuracy Score: \", '{:,.3f}'.format(float(accuracy_score(test, pred)) * 100), \"%\")\n",
        "    print(\"     Precision: \", '{:,.3f}'.format(float(precision_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    print(\"        Recall: \", '{:,.3f}'.format(float(recall_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    print(\"      F1 score: \", '{:,.3f}'.format(float(f1_score(test, pred, average='macro')) * 100), \"%\")\n",
        "    \n",
        "#Let's split the data into train/test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test set size of 20% of the data and the random seed 42 <3\n",
        "X_train, X_test, y_train, y_test = train_test_split(features.toarray(),idx_cos, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train size:\", len(X_train))\n",
        "print(\"X_test size:\", len(X_test), \"\\n\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train size: 1724\n",
            "X_test size: 431 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwXcuHbWx0G5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "27477c5c-b021-435f-8d9e-b980af66b172"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# SGD instance\n",
        "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3, random_state=42, n_jobs=4)\n",
        "# train SGD\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "\n",
        "# cross validation predictions\n",
        "sgd_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3, n_jobs=4)\n",
        "\n",
        "# print out the classification report\n",
        "classification_report(\"Stochastic Gradient Descent Report (Training Set)\", y_train, sgd_pred)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stochastic Gradient Descent Report (Training Set) :\n",
            "\n",
            "Accuracy Score:  84.397 %\n",
            "     Precision:  88.455 %\n",
            "        Recall:  88.385 %\n",
            "      F1 score:  88.186 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iqlk7Sz_x0G9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "394338ce-dd50-4f19-b98a-e16dbb8ab4a0"
      },
      "source": [
        "# cross validation predictions\n",
        "sgd_pred = cross_val_predict(sgd_clf, X_test, y_test, cv=3, n_jobs=4)\n",
        "\n",
        "# print out the classification report\n",
        "classification_report(\"Stochastic Gradient Descent Report (Training Set)\", y_test, sgd_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stochastic Gradient Descent Report (Training Set) :\n",
            "\n",
            "Accuracy Score:  72.854 %\n",
            "     Precision:  80.672 %\n",
            "        Recall:  73.825 %\n",
            "      F1 score:  75.214 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8iSoLZnRx0HD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0dffb73-5cb3-475c-faef-8af810546e0c"
      },
      "source": [
        "sgd_cv_score = cross_val_score(sgd_clf, features.toarray(), idx_cor, cv=10)\n",
        "print(\"Mean cv Score - SGD: {:,.3f}\".format(float(sgd_cv_score.mean()) * 100), \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv Score - SGD: 82.691 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}