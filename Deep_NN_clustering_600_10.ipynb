{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-NN_clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mxZOMIDXXau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import math\n",
        "import sys\n",
        "import logging\n",
        "#-----------------------------------------------------------\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from IPython.display import clear_output\n",
        "from scipy.spatial.distance import squareform, pdist\n",
        "from sklearn.preprocessing import normalize\n",
        "from numpy import linalg as LA\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from math import sqrt\n",
        "#----------------------------------------------\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from optparse import OptionParser\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqX8ZR5wsGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardization(X):\n",
        "    return normalize(X, axis=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKho_sESzQMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laplacian(A):\n",
        "    S = np.sum(A, 0)\n",
        "    D = np.diag(S)\n",
        "    D = LA.matrix_power(D, -1)\n",
        "    L = np.dot(D, A)\n",
        "    return L"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUSpsQozS-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization(V):\n",
        "    return (V - min(V)) / (max(V) - min(V))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndbmGyJzWIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Correlation_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'correlation')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHrGqwRnzY-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cosine_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'cosine')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV0iHGWzcp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Similarity_Dataset_Iterator():\n",
        "    def __init__(self, data, labels, similarity):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.matrix = similarity.get_matrix(data)\n",
        "        self.data_size = self.matrix.shape[0]\n",
        "        self.current_index = 0\n",
        "    def next_batch(self, num):\n",
        "        data=self.matrix.transpose()\n",
        "        labels=self.labels\n",
        "        idx = np.arange(0 , len(data))\n",
        "        np.random.shuffle(idx)\n",
        "        idx = idx[:num]\n",
        "        data_shuffle = [data[ i] for i in idx]\n",
        "        labels_shuffle = [labels[ i] for i in idx]\n",
        "        return data_shuffle, labels_shuffle\n",
        "    def whole_dataset(self):\n",
        "        return (self.matrix.transpose(), self.labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n076atQh0kmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4694b0f3-3b5c-4499-a529-d8cf00cb9b45"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3U9x9aT05Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6449bcd8-47ba-4954-884f-d3ec8ce644e5"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/edited_topics_all_news.csv')\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  processed_topic\n",
              "0           0  ...      west bengal\n",
              "1           1  ...      west bengal\n",
              "2           2  ...      west bengal\n",
              "3           3  ...      west bengal\n",
              "4           4  ...      west bengal\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0GlS3WC1Udh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.dropna(subset=['content'], inplace = True)\n",
        "#df.dropna(subset=['topic'], inplace = True)\n",
        "df['your column name'].isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dat6uH3E2OmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cced1ae-d391-4f6d-f054-a8e03a90c9ed"
      },
      "source": [
        "#len(df.content.unique()),  len(df.content), len(df.topic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1204, 1304, 1304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S87soJgE2SZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "54489033-c90a-4c52-d068-6f818c65f370"
      },
      "source": [
        "#df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_id          0\n",
              "topic        0\n",
              "heading    383\n",
              "content      0\n",
              "tags        68\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PbPTbyu2deC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065c554a-dd09-4d56-8748-16017fc69e32"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1274, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-XKjCAS48pD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3ad50f97-3371-499a-d3ab-f8d4bcf72e1f"
      },
      "source": [
        "#import re\n",
        "\n",
        "#import gensim\n",
        "#from gensim import corpora,models\n",
        "#from gensim.utils import simple_preprocess\n",
        "#from gensim.models import CoherenceModel\n",
        "#from gensim.parsing.preprocessing import STOPWORDS\n",
        "#from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "#from nltk.stem.porter import *\n",
        "#import numpy as np\n",
        "#np.random.seed(2018)\n",
        "\n",
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2dezj2a48qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemmer = SnowballStemmer(language='english',ignore_stopwords=True)\n",
        "#def lemmatize_stemming(text):\n",
        "#    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "#def preprocess(text):\n",
        "    #result = []\n",
        "   # for token in gensim.utils.simple_preprocess(text):\n",
        "   #     if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "   #         result.append(lemmatize_stemming(token))\n",
        "  #  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws57P9WE48uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "3eb64829-6726-4133-b90f-7e0f43b0be4e"
      },
      "source": [
        "#doc_sample = df['content'][0]\n",
        "#print('original document: ')\n",
        "#words = []\n",
        "#for word in doc_sample.split(' '):\n",
        "#    words.append(word)\n",
        "#print(words)\n",
        "#print('\\n\\n tokenized and lemmatized document: ')\n",
        "#print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['[\"Garbage-lined', 'streets', 'and', 'overflowing', 'drains', 'across', 'Salt', 'Lake', 'have', 'sparked', 'fear', 'of', 'an', 'outbreak', 'of', 'enteric', 'diseases', 'and', 'are', 'forcing', 'residents', 'to', 'keep', 'the', 'windows', 'and', 'doors', 'of', 'their', 'houses', 'firmly', 'shut.\",\"Residents', 'said', 'most', 'of', 'the', '150', 'tonnes', 'of', 'the', 'garbage', 'Salt', 'Lake', 'generates', 'every', 'day', 'is', 'accumulating', 'across', 'the', '33.5sq', 'km', 'township.\",\"“At', 'this', 'rate,', 'Salt', 'Lake', 'will', 'soon', 'become', 'Dhapa.', 'This', 'is', 'happening', 'at', 'a', 'time', 'the', 'authorities', 'as', 'well', 'as', 'residents', 'need', 'to', 'focus', 'on', 'hygiene', 'to', 'combat', 'Covid', 'and', 'dengue,”', 'said', 'a', 'resident,', 'hand', 'firmly', 'on', 'his', 'nose.\",\"“It', 'is', 'true', 'that', 'garbage', 'has', 'accumulated', 'in', 'some', 'places', 'but', 'I', 'don’t', 'think', 'it', 'is', 'a', 'big', 'problem.', 'We', 'will', 'clear', 'it', 'within', 'seven', 'days,”', 'said', 'Debasish', 'Jana,', 'the', 'mayoral', 'council', 'member', 'in', 'charge', 'of', 'solid', 'waste', 'management', 'at', 'the', 'Bidhannagar', 'Municipal', 'Corporation.\",\"Asked', 'why', 'the', 'civic', 'body', 'has', 'not', 'yet', 'been', 'able', 'to', 'solve', 'a', '“simple', 'problem”,', 'Jana', 'said:', '“Several', 'of', 'our', 'trucks', 'are', 'out', 'of', 'order,', 'but', 'our', 'sweepers', 'are', 'at', 'work', 'all', 'day.', 'It’s', 'just', 'that', 'accumulated', 'garbage', 'isn’t', 'being', 'removed', 'regularly', 'from', 'a', 'few', 'areas.”\",\"For', 'five', 'days', 'a', 'week,', 'Buddhadeb', 'Basu,', 'a', 'resident', 'of', 'DB', 'block,', 'near', 'City', 'Centre,', 'is', 'having', 'to', 'dump', 'household', 'waste', 'at', 'the', 'neighbourhood', 'compactor', 'station', 'overflowing', 'with', 'garbage.', 'He', 'doesn’t', 'have', 'a', 'choice.', 'His', 'neighbours,', 'too,', 'are', 'doing', 'the', 'same.\",\"“Civic', 'workers', 'would', 'previously', 'collect', 'garbage', 'from', 'our', 'doorstep', 'every', 'day.', 'Now', 'they', 'come', 'hardly', 'twice', 'a', 'week.', 'They', 'are', 'not', 'even', 'taking', 'away', 'garbage', 'from', 'near', 'the', 'compactor', 'station.', 'The', 'entire', 'area', 'stinks,”', 'the', '62-year-old', 'told', '\",\"The', 'Telegraph\",\".\",\"This', 'newspaper', 'drove', 'around', 'the', 'township', 'on', 'Monday', 'and', 'found', 'scarcely', 'any', 'block', 'or', 'compactor', 'station', 'that', 'did', 'not', 'have', 'a', 'heap', 'of', 'garbage', 'lying', 'around.\",\"The', 'areas', 'near', 'City', 'Centre', 'and', 'the', 'CGO', 'Complex', 'looked', 'the', 'dirtiest.', 'The', 'situation', 'was', 'similar', 'in', 'the', 'AE,', 'AB,', 'BC,', 'BB,', 'and', 'IC', 'blocks.\",\"A', '20-metre', 'stretch', 'from', 'the', 'City', 'Centre', 'Metro', 'station', 'till', 'Bidhannagar', 'College', 'had', 'almost', 'half', 'the', 'carriageway', 'swallowed', 'by', 'garbage.', 'The', 'entire', 'area', 'had', 'flies', 'swarming', 'around,', 'while', 'several', 'dogs', 'and', 'cows', 'were', 'seen', 'rummaging', 'through', 'the', 'garbage', 'for', 'food.\",\"Passers-by', 'were', 'seen', 'holding', 'handkerchiefs', 'on', 'their', 'noses', 'despite', 'wearing', 'masks.\",\"“The', 'stench', 'from', 'the', 'garbage', 'in', 'front', 'of', 'our', 'house', 'is', 'so', 'overpowering', 'that', 'we', 'keep', 'the', 'windows', 'of', 'our', 'house', 'shut,”', 'said', 'Prakash', 'Agarwal,', 'a', 'resident', 'of', 'EC', 'Block.\",\"A', 'civic', 'official', 'blamed', 'the', 'combination', 'of', 'staff', 'shortage', 'and', 'defunct', 'garbage', 'collection', 'trucks', 'for', 'the', 'sorry', 'state', 'of', 'affairs.\\xa0', '“Many', 'men', 'are', 'not', 'reporting', 'for', 'work', 'out', 'of', 'fear', 'of', 'contracting', 'the', 'coronavirus', 'and', 'also', 'because', 'local', 'trains', 'are', 'not', 'running,”', 'the', 'official', 'said.', '“There', 'used', 'to', 'be', '250', 'sweepers.', 'Now,', 'there', 'are', 'only', 'half', 'that\\xa0number.”\",\"Mayoral', 'council', 'member', 'Jana', 'said', 'many', 'workers', 'who', 'were', 'involved', 'in', 'collection', 'of', 'garbage', 'were', 'now', 'selling', 'vegetables', 'or', 'involved', 'in', 'other', 'activities.', '“We', 'are', 'trying', 'to', 'hire', 'personnel', 'but', 'the', 'pandemic', 'is', 'coming', 'in', 'the', 'way,”', 'he', 'said.\",\"To', 'add', 'to', 'the', 'problem,', 'sources', 'said,', 'many', 'handcarts', 'and', 'vans', 'have', 'broken', 'down.\"]']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['garbag', 'line', 'street', 'overflow', 'drain', 'salt', 'lake', 'spark', 'fear', 'outbreak', 'enter', 'diseas', 'forc', 'resid', 'window', 'door', 'hous', 'firm', 'shut', 'resid', 'say', 'tonn', 'garbag', 'salt', 'lake', 'generat', 'accumul', 'township', 'rate', 'salt', 'lake', 'soon', 'dhapa', 'happen', 'time', 'author', 'resid', 'need', 'focus', 'hygien', 'combat', 'covid', 'dengu', 'say', 'resid', 'hand', 'firm', 'nose', 'true', 'garbag', 'accumul', 'place', 'think', 'problem', 'clear', 'seven', 'day', 'say', 'debasish', 'jana', 'mayor', 'council', 'member', 'charg', 'solid', 'wast', 'manag', 'bidhannagar', 'municip', 'corpor', 'ask', 'civic', 'bodi', 'abl', 'solv', 'simpl', 'problem', 'jana', 'say', 'truck', 'order', 'sweeper', 'work', 'accumul', 'garbag', 'remov', 'regular', 'area', 'day', 'week', 'buddhadeb', 'basu', 'resid', 'block', 'near', 'citi', 'centr', 'have', 'dump', 'household', 'wast', 'neighbourhood', 'compactor', 'station', 'overflow', 'garbag', 'choic', 'neighbour', 'civic', 'worker', 'previous', 'collect', 'garbag', 'doorstep', 'come', 'hard', 'twice', 'week', 'take', 'away', 'garbag', 'near', 'compactor', 'station', 'entir', 'area', 'stink', 'year', 'tell', 'telegraph', 'newspap', 'drive', 'township', 'monday', 'scarc', 'block', 'compactor', 'station', 'heap', 'garbag', 'lie', 'area', 'near', 'citi', 'centr', 'complex', 'look', 'dirtiest', 'situat', 'similar', 'block', 'metr', 'stretch', 'citi', 'centr', 'metro', 'station', 'till', 'bidhannagar', 'colleg', 'half', 'carriageway', 'swallow', 'garbag', 'entir', 'area', 'fli', 'swarm', 'dog', 'cow', 'see', 'rummag', 'garbag', 'food', 'passer', 'see', 'hold', 'handkerchief', 'nose', 'despit', 'wear', 'mask', 'stench', 'garbag', 'hous', 'overpow', 'window', 'hous', 'shut', 'say', 'prakash', 'agarw', 'resid', 'block', 'civic', 'offici', 'blame', 'combin', 'staff', 'shortag', 'defunct', 'garbag', 'collect', 'truck', 'sorri', 'state', 'affair', 'report', 'work', 'fear', 'contract', 'coronavirus', 'local', 'train', 'run', 'offici', 'say', 'sweeper', 'half', 'number', 'mayor', 'council', 'member', 'jana', 'say', 'worker', 'involv', 'collect', 'garbag', 'sell', 'veget', 'involv', 'activ', 'tri', 'hire', 'personnel', 'pandem', 'come', 'say', 'problem', 'sourc', 'say', 'handcart', 'van', 'break']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzga2tYu48mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e1bc92a9-01a3-4378-c4b4-4b6fa441bcc9"
      },
      "source": [
        "#df['processed_heading'] = df['heading'].map(preprocess)\n",
        "#df['processed_content'] = df['content'].map(preprocess)\n",
        "#df['processed_topic'] = df['topic'].map(preprocess)\n",
        "#df['processed_heading'] = df['processed_heading'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_content'] = df['processed_content'].apply(lambda x: ' '.join(x))\n",
        "#df['processed_topic'] = df['processed_topic'].apply(lambda x: ' '.join(x))\n",
        "#df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id  ... processed_topic\n",
              "0  5f04d2481f35ed6864839349  ...     west bengal\n",
              "1  5f04d24b1f35ed686483934a  ...     west bengal\n",
              "2  5f04d24d1f35ed686483934b  ...     west bengal\n",
              "3  5f04d2501f35ed686483934c  ...     west bengal\n",
              "4  5f04d2531f35ed686483934d  ...     west bengal\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfAJav1NLOVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/edited_all_news.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsa-O7Bw48kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from collections import Counter\n",
        "#Counter(df.topic[700:])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBuLrsC3FWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_NewsGroup_data(similarity):    \n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(levelname)s %(message)s')\n",
        "    op = OptionParser()\n",
        "    op.add_option(\"--lsa\", dest=\"n_components\", type=\"int\",\n",
        "                  help=\"Preprocess documents with latent semantic analysis.\")    \n",
        "    op.add_option(\"--no-idf\",action=\"store_false\", dest=\"use_idf\", default=True,\n",
        "                  help=\"Disable Inverse Document Frequency feature weighting.\")\n",
        "    op.add_option(\"--use-hashing\", action=\"store_true\", default=False,\n",
        "                  help=\"Use a hashing feature vectorizer\")\n",
        "    op.add_option(\"--n-features\", type=int, default=10000,\n",
        "                  help=\"Maximum number of features to extract from text.\")    \n",
        "    def is_interactive():\n",
        "        return not hasattr(sys.modules['__main__'], '__file__')\n",
        "    argv = [] if is_interactive() else sys.argv[1:]\n",
        "    (opts, args) = op.parse_args(argv)\n",
        "    if len(args) > 0:\n",
        "        op.error(\"this script takes no arguments.\")\n",
        "        sys.exit(1)\n",
        "        \n",
        "    labels = df.processed_topic[:600]\n",
        "    data = df.processed_content[:600]\n",
        "    #true_k = np.unique(labels).shape[0]\n",
        "    vectorizer = TfidfVectorizer(max_features=opts.n_features,use_idf=opts.use_idf)\n",
        "    X = vectorizer.fit_transform(data)\n",
        "    if opts.n_components:\n",
        "        svd = TruncatedSVD(opts.n_components)\n",
        "        normalizer = Normalizer(copy=False)\n",
        "        lsa = make_pipeline(svd, normalizer)\n",
        "        X = lsa.fit_transform(X)\n",
        "        explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    return Similarity_Dataset_Iterator(X.toarray(), labels, similarity)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZHYkqiV6Gsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Correlation_Similarity as similarity dataset.\n",
        "trainSet_correlation = read_NewsGroup_data(Correlation_Similarity())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZQ9wy646MCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Cosine_Similarity as similarity dataset.\n",
        "trainSet_cosine = read_NewsGroup_data(Cosine_Similarity())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIbetWyC6PMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27f297f8-a240-411f-b1b3-0175b13dc423"
      },
      "source": [
        "n_input = trainSet_correlation.data_size #--------- Number of input data.\n",
        "print(n_input)\n",
        "# Define the number of hidden layer. \n",
        "if n_input >= 1024:\n",
        "    Nn = int(2048)\n",
        "elif n_input >= 512:\n",
        "    Nn = int(1024)\n",
        "elif n_input >= 256:\n",
        "    Nn = int(512)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3m9vsd6X0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden_1 = int(Nn/2) #-------------------- The autoencoder hidden layer 1.\n",
        "n_code = str(int(n_hidden_1/2)) #----------- The number of output dimension value."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeA7y-46cOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0c0e9c8e-7b15-4213-a903-75d1820aa6ef"
      },
      "source": [
        "print('Layer 1: -----------', n_input)\n",
        "print('Layer 2: -----------', n_hidden_1)\n",
        "print('Layer 3: -----------', int(n_code))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1: ----------- 600\n",
            "Layer 2: ----------- 512\n",
            "Layer 3: ----------- 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McRy7WF6gX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means_(X, n_clusters):\n",
        "    kmeans_centroids,_ =  kmeans(X, n_clusters)\n",
        "    kmeans_, _ = vq(X, kmeans_centroids)\n",
        "    return kmeans_"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQwaaHt6nG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, n_code, mode_train):    \n",
        "    with tf.variable_scope(\"encoder\"):        \n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(x, [n_input, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"embedded\"):\n",
        "            code = layer(hidden_1, [n_hidden_1, n_code], [n_code], mode_train)\n",
        "    return code"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9rxQoz6p6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(code, n_code, mode_train):\n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(code, [n_code, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"reconstructed\"):\n",
        "            output = layer(hidden_1, [n_hidden_1, n_input], [n_input], mode_train)\n",
        "    return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8C3fm4r6tdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(x, n_out, mode_train):\n",
        "    beta_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    gamma_initialize = tf.constant_initializer(value=0.1, dtype=tf.float32)\n",
        "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_initialize)\n",
        "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_initialize)\n",
        "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
        "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
        "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
        "    def mean_var():\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
        "    mean, var = control_flow_ops.cond(mode_train, mean_var, lambda: (ema_mean, ema_var))\n",
        "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
        "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-08, True)\n",
        "    return tf.reshape(normed, [-1, n_out])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPomeQMg61f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(input, weight_shape, bias_shape, mode_train):\n",
        "    value_initialize = (1.0 / weight_shape[0] ** 0.5)\n",
        "    weight_initialize = tf.random_normal_initializer(stddev = value_initialize, seed = None)\n",
        "    bias_initialize = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    w = tf.get_variable(\"w\", weight_shape, initializer=weight_initialize)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_initialize)\n",
        "    return tf.nn.sigmoid(batch_norm((tf.matmul(input, w) + b), weight_shape[1], mode_train))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuq5HnwW642G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(reconstructed, x):\n",
        "    with tf.variable_scope(\"train\"):\n",
        "        train_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(reconstructed, x)), 1))\n",
        "        return train_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAIvq9769F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, learning_rate, beta1, beta2, global_step):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIEYZXv7AUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd70e3f5-8770-4b06-a5d0-c1439c1aa354"
      },
      "source": [
        "# Parameters\n",
        "n_layers = 3 #------------------------------ Number of Neural Networks Layers.\n",
        "beta1 = 0.9 #------------------------------- The decay rate 1.  \n",
        "beta2 = 0.999 #----------------------------- The decay rate 2.\n",
        "learning_rate = (beta1/n_input) #----------- The learning rate.\n",
        "n_batch = math.ceil(sqrt(sqrt(n_input))) #-- Number of selection data in per step.\n",
        "n_backpro = math.ceil(n_input/n_batch) #---- Number of Backpro in per epoch.\n",
        "n_clusters = 10 #---------------------------- Number of clusters.\n",
        "\n",
        "print(n_batch)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPCpkiff7Kxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cor, labels_cor = trainSet_correlation.whole_dataset() #-- Allocation of data and labels\n",
        "data_cos, labels_cos = trainSet_cosine.whole_dataset() #------- Allocation of data and labels"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5XoVMB7glv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cor=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cor=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cor=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhSKWs97k7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "3f6ad8ab-e59b-42a8-e073-2c373b72906c"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_correlation.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "                \n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cor = sess.run(code, feed_dict={x: data_cor, mode_train: False})        \n",
        "    idx_cor = k_means_(ae_codes_cor, n_clusters)\n",
        "    ae_nmi_cor = normalized_mutual_info_score(labels_cor, idx_cor)\n",
        "    ae_nmi_cor = ae_nmi_cor*100\n",
        "    results_cor.append(ae_nmi_cor)    \n",
        "    seeding_cor.append(i)\n",
        "    loss_cost_cor.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cor, new_cost, i))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-5221a4ca5356>:4: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-19 13:30:01,039 WARNING From <ipython-input-26-5221a4ca5356>:4: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-19 13:30:01,056 WARNING From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 39.08 and new cost is: 71.17 in 1 step of seeding.\n",
            "NMI score for AE is: 40.41 and new cost is: 71.83 in 2 step of seeding.\n",
            "NMI score for AE is: 42.73 and new cost is: 70.61 in 3 step of seeding.\n",
            "NMI score for AE is: 39.36 and new cost is: 71.09 in 4 step of seeding.\n",
            "NMI score for AE is: 39.45 and new cost is: 70.82 in 5 step of seeding.\n",
            "NMI score for AE is: 40.16 and new cost is: 71.32 in 6 step of seeding.\n",
            "NMI score for AE is: 41.93 and new cost is: 71.34 in 7 step of seeding.\n",
            "NMI score for AE is: 41.12 and new cost is: 71.54 in 8 step of seeding.\n",
            "NMI score for AE is: 40.98 and new cost is: 71.83 in 9 step of seeding.\n",
            "NMI score for AE is: 40.87 and new cost is: 71.67 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ulspmFn7tu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c34a3f6-2b9f-40a6-a25d-72089d2c2750"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Correlation is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cor), (np.mean(results_cor))))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Correlation is >>> 40.61 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND1MKJ6iE8Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e0ab3f07-57dd-4780-cfcc-1b84b277cd9a"
      },
      "source": [
        "results_cor"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39.082770264533565,\n",
              " 40.412761541376554,\n",
              " 42.7333190813439,\n",
              " 39.35683889170172,\n",
              " 39.45122418614645,\n",
              " 40.16017750156561,\n",
              " 41.9342824860606,\n",
              " 41.11680555252199,\n",
              " 40.981296445334415,\n",
              " 40.87314097595732]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXecHj3NE8Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cos=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cos=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cos=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERMUm14E8SQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8ad2ebd5-3185-41d9-b10f-d7252ec3deeb"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    with tf.Graph().as_default():    \n",
        "        with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "            x = tf.placeholder(\"float\", [None, n_input])   \n",
        "            mode_train = tf.placeholder(tf.bool)\n",
        "            code = encoder(x, int(n_code), mode_train)\n",
        "            reconstructed = decoder(code, int(n_code), mode_train)\n",
        "            cost = loss(reconstructed, x)\n",
        "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "            train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "            sess = tf.Session()\n",
        "            init_op = tf.global_variables_initializer()\n",
        "            sess.run(init_op)\n",
        "            # Training cycle\n",
        "            for ii in range(n_layers):\n",
        "                # Fit training with backpropagation using batch data.\n",
        "                for jj in range(n_backpro):\n",
        "                    miniData, _ = trainSet_cosine.next_batch(n_batch)\n",
        "                    _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                              mode_train: True})       \n",
        "                #------------------------- End of the Optimization ------------------------------\n",
        "\n",
        "    # Getting embedded codes and running K-Means on them.\n",
        "    ae_codes_cos = sess.run(code, feed_dict={x: data_cos, mode_train: False})        \n",
        "    idx_cos = k_means_(ae_codes_cos, n_clusters)\n",
        "    ae_nmi_cos = normalized_mutual_info_score(labels_cos, idx_cos)\n",
        "    ae_nmi_cos = ae_nmi_cos*100\n",
        "    results_cos.append(ae_nmi_cos)    \n",
        "    seeding_cos.append(i)\n",
        "    loss_cost_cos.append(new_cost)    \n",
        "    print(\"NMI score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step of seeding.\"\n",
        "          .format(ae_nmi_cos, new_cost, i))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMI score for AE is: 38.92 and new cost is: 72.09 in 1 step of seeding.\n",
            "NMI score for AE is: 38.94 and new cost is: 72.62 in 2 step of seeding.\n",
            "NMI score for AE is: 42.56 and new cost is: 72.19 in 3 step of seeding.\n",
            "NMI score for AE is: 43.40 and new cost is: 71.73 in 4 step of seeding.\n",
            "NMI score for AE is: 45.00 and new cost is: 72.77 in 5 step of seeding.\n",
            "NMI score for AE is: 42.73 and new cost is: 72.32 in 6 step of seeding.\n",
            "NMI score for AE is: 41.96 and new cost is: 71.15 in 7 step of seeding.\n",
            "NMI score for AE is: 42.27 and new cost is: 71.19 in 8 step of seeding.\n",
            "NMI score for AE is: 40.38 and new cost is: 72.76 in 9 step of seeding.\n",
            "NMI score for AE is: 43.34 and new cost is: 72.49 in 10 step of seeding.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL6sjMQEFIXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4af41cce-4c2c-494a-f9bc-6a5c08540d92"
      },
      "source": [
        "print(\"The Average of NMI Score for >>> {:d} <<< Random Factors in Autoencoder Cosine is >>> {:0.2f} <<<\"\n",
        "      .format(len(seeding_cos), (np.mean(results_cos))))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Average of NMI Score for >>> 10 <<< Random Factors in Autoencoder Cosine is >>> 41.95 <<<\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQmt5pjFIa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c5b24a47-071e-4799-f929-e92a489d2e39"
      },
      "source": [
        "results_cos"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38.91893999220489,\n",
              " 38.94276123288829,\n",
              " 42.56282824619583,\n",
              " 43.40201538250813,\n",
              " 45.001253496212776,\n",
              " 42.732865193769406,\n",
              " 41.96298667025162,\n",
              " 42.274643902729856,\n",
              " 40.375915386455596,\n",
              " 43.33501885111674]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3afCnSOFIVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bb3f68a8-529b-4009-fbb9-3fc432f84f25"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "plt.ylim(30,101)\n",
        "plt.plot(seeding_cor, results_cor, label='Autoencoder Correlation Simialrity', color='m', marker='o')\n",
        "plt.plot(seeding_cos, results_cos, label='Autoencoder Cosine Simialrity', color='g', marker='s')\n",
        "plt.xlabel('Number of Seeding.')\n",
        "plt.ylabel('NMI')\n",
        "plt.grid()\n",
        "plt.title('The Average of NMI Scores')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIhu5zg4FeA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f49bc6b7-8630-4afc-c4fe-476df4620428"
      },
      "source": [
        "print(\"Autoencoder Clustering on Cosine: ------------ {:0.2f}\".format(np.mean(results_cos)))\n",
        "print(\"Autoencoder Clustering on Correlation: ------- {:0.2f}\".format(np.mean(results_cor)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder Clustering on Cosine: ------------ 41.95\n",
            "Autoencoder Clustering on Correlation: ------- 40.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uGhkhbeRmFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}