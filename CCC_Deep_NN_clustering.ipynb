{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CCC Deep-NN_clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mxZOMIDXXau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import math\n",
        "import sys\n",
        "import logging\n",
        "#-----------------------------------------------------------\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from IPython.display import clear_output\n",
        "from scipy.spatial.distance import squareform, pdist\n",
        "from sklearn.preprocessing import normalize\n",
        "from numpy import linalg as LA\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from math import sqrt\n",
        "#----------------------------------------------\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from optparse import OptionParser\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqX8ZR5wsGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardization(X):\n",
        "    return normalize(X, axis=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKho_sESzQMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laplacian(A):\n",
        "    S = np.sum(A, 0)\n",
        "    D = np.diag(S)\n",
        "    D = LA.matrix_power(D, -1)\n",
        "    L = np.dot(D, A)\n",
        "    return L"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUSpsQozS-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalization(V):\n",
        "    return (V - min(V)) / (max(V) - min(V))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndbmGyJzWIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Correlation_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'correlation')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHrGqwRnzY-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cosine_Similarity:\n",
        "    def get_matrix(self, Data):\n",
        "        X = standardization(Data)\n",
        "        X = pdist(X, 'cosine')\n",
        "        X = squareform(X)\n",
        "        L = laplacian(X)\n",
        "        Y = np.apply_along_axis(normalization, 1, L)\n",
        "        return Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV0iHGWzcp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Similarity_Dataset_Iterator():\n",
        "    def __init__(self, data, labels, similarity):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.matrix = similarity.get_matrix(data)\n",
        "        self.data_size = self.matrix.shape[0]\n",
        "        self.current_index = 0\n",
        "    def next_batch(self, num):\n",
        "        data=self.matrix.transpose()\n",
        "        labels=self.labels\n",
        "        idx = np.arange(0 , len(data))\n",
        "        np.random.shuffle(idx)\n",
        "        idx = idx[:num]\n",
        "        data_shuffle = [data[ i] for i in idx]\n",
        "        labels_shuffle = [labels[ i] for i in idx]\n",
        "        return data_shuffle, labels_shuffle\n",
        "    def whole_dataset(self):\n",
        "        return (self.matrix.transpose(), self.labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n076atQh0kmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3U9x9aT05Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6f4fe20f-f7d6-42f1-84db-83a9247dc060"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/edited_all_news.csv')\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>heading</th>\n",
              "      <th>content</th>\n",
              "      <th>tags</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>processed_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5f04d2481f35ed6864839349</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Garbage-lined streets and overflowing drains...</td>\n",
              "      <td>[\"Garbage\",\"Salt-lake\",\"Bidhannagar-municipal-...</td>\n",
              "      <td>garbag line street overflow drain salt lake sp...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5f04d24b1f35ed686483934a</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"The Bengal government will set up a plasma b...</td>\n",
              "      <td>[\"Calcutta-medical-college-and-hospital\",\"Coro...</td>\n",
              "      <td>bengal govern plasma bank calcutta medic colle...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5f04d24d1f35ed686483934b</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Bengal set another 24-hour record on Monday ...</td>\n",
              "      <td>[\"Lockdown\",\"Coronavirus\",\"Quarantine\"]</td>\n",
              "      <td>bengal hour record monday highest number covid...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5f04d2501f35ed686483934c</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Chief minister Mamata Banerjee on Monday sai...</td>\n",
              "      <td>[\"Mamata-banerjee\",\"Cyclone-amphan\"]</td>\n",
              "      <td>chief minist mamata banerje monday say problem...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5f04d2531f35ed686483934d</td>\n",
              "      <td>[\"West-bengal\"]</td>\n",
              "      <td>[\"\\n                        \",\"\\n             ...</td>\n",
              "      <td>[\"Some senior historians have raised questions...</td>\n",
              "      <td>[\"Jagat-prakash-nadda\",\"Bharatiya-janata-party...</td>\n",
              "      <td>senior historian rais question attempt pitch b...</td>\n",
              "      <td>west bengal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... processed_topic\n",
              "0           0  ...     west bengal\n",
              "1           1  ...     west bengal\n",
              "2           2  ...     west bengal\n",
              "3           3  ...     west bengal\n",
              "4           4  ...     west bengal\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsa-O7Bw48kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d65c12c3-263c-4a11-f4bf-b8815402461d"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(df.topic[700:])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'[\"Business\"]': 57,\n",
              "         '[\"City\"]': 22,\n",
              "         '[\"DHNS\"]': 1,\n",
              "         '[\"Entertainment\"]': 34,\n",
              "         '[\"International\"]': 27,\n",
              "         '[\"Lifestyle\"]': 36,\n",
              "         '[\"Metrolife\"]': 12,\n",
              "         '[\"Nation\"]': 109,\n",
              "         '[\"National\"]': 62,\n",
              "         '[\"Opinion\"]': 58,\n",
              "         '[\"People\"]': 1,\n",
              "         '[\"Science and Environment\"]': 17,\n",
              "         '[\"Science\"]': 3,\n",
              "         '[\"Specials\"]': 15,\n",
              "         '[\"Spectrum\"]': 2,\n",
              "         '[\"Sports\"]': 44,\n",
              "         '[\"State\"]': 31,\n",
              "         '[\"Sunday Chronicle\"]': 2,\n",
              "         '[\"Sunday Herald\"]': 1,\n",
              "         '[\"Supplements\"]': 5,\n",
              "         '[\"Technology\"]': 23,\n",
              "         '[\"World\"]': 42})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBuLrsC3FWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_NewsGroup_data(similarity):    \n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(levelname)s %(message)s')\n",
        "    op = OptionParser()\n",
        "    op.add_option(\"--lsa\", dest=\"n_components\", type=\"int\",\n",
        "                  help=\"Preprocess documents with latent semantic analysis.\")    \n",
        "    op.add_option(\"--no-idf\",action=\"store_false\", dest=\"use_idf\", default=True,\n",
        "                  help=\"Disable Inverse Document Frequency feature weighting.\")\n",
        "    op.add_option(\"--use-hashing\", action=\"store_true\", default=False,\n",
        "                  help=\"Use a hashing feature vectorizer\")\n",
        "    op.add_option(\"--n-features\", type=int, default=10000,\n",
        "                  help=\"Maximum number of features to extract from text.\")    \n",
        "    def is_interactive():\n",
        "        return not hasattr(sys.modules['__main__'], '__file__')\n",
        "    argv = [] if is_interactive() else sys.argv[1:]\n",
        "    (opts, args) = op.parse_args(argv)\n",
        "    if len(args) > 0:\n",
        "        op.error(\"this script takes no arguments.\")\n",
        "        sys.exit(1)\n",
        "        \n",
        "    labels = df.processed_topic[700:]\n",
        "    #true_k = np.unique(labels).shape[0]\n",
        "    vectorizer = TfidfVectorizer(max_features=opts.n_features,use_idf=opts.use_idf)\n",
        "    X = vectorizer.fit_transform(df.processed_content[700:])\n",
        "    if opts.n_components:\n",
        "        svd = TruncatedSVD(opts.n_components)\n",
        "        normalizer = Normalizer(copy=False)\n",
        "        lsa = make_pipeline(svd, normalizer)\n",
        "        X = lsa.fit_transform(X)\n",
        "        explained_variance = svd.explained_variance_ratio_.sum()\n",
        "    return Similarity_Dataset_Iterator(X.toarray(), labels, similarity)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZHYkqiV6Gsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Correlation_Similarity as similarity dataset.\n",
        "trainSet_correlation = read_NewsGroup_data(Correlation_Similarity())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZQ9wy646MCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Call Cosine_Similarity as similarity dataset.\n",
        "trainSet_cosine = read_NewsGroup_data(Cosine_Similarity())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIbetWyC6PMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b0de0da-10f8-4269-852b-3e530a6e8559"
      },
      "source": [
        "n_input = trainSet_correlation.data_size #--------- Number of input data.\n",
        "print(n_input)\n",
        "# Define the number of hidden layer. \n",
        "if n_input >= 1024:\n",
        "    Nn = int(2048)\n",
        "elif n_input >= 512:\n",
        "    Nn = int(1024)\n",
        "elif n_input >= 256:\n",
        "    Nn = int(512)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3m9vsd6X0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden_1 = int(Nn/2) #-------------------- The autoencoder hidden layer 1.\n",
        "n_code = str(int(n_hidden_1/2)) #----------- The number of output dimension value."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DeA7y-46cOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bf10a9a2-859d-4bab-e517-ae972fc78059"
      },
      "source": [
        "print('Layer 1: -----------', n_input)\n",
        "print('Layer 2: -----------', n_hidden_1)\n",
        "print('Layer 3: -----------', int(n_code))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1: ----------- 604\n",
            "Layer 2: ----------- 512\n",
            "Layer 3: ----------- 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McRy7WF6gX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means_(X, n_clusters):\n",
        "    kmeans_centroids,_ =  kmeans(X, n_clusters)\n",
        "    kmeans_, _ = vq(X, kmeans_centroids)\n",
        "    return kmeans_"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQwaaHt6nG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, n_code, mode_train):    \n",
        "    with tf.variable_scope(\"encoder\"):        \n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(x, [n_input, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"embedded\"):\n",
        "            code = layer(hidden_1, [n_hidden_1, n_code], [n_code], mode_train)\n",
        "    return code"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu9rxQoz6p6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(code, n_code, mode_train):\n",
        "    with tf.variable_scope(\"decoder\"):\n",
        "        with tf.variable_scope(\"hidden-layer-1\"):\n",
        "            hidden_1 = layer(code, [n_code, n_hidden_1], [n_hidden_1], mode_train)\n",
        "        with tf.variable_scope(\"reconstructed\"):\n",
        "            output = layer(hidden_1, [n_hidden_1, n_input], [n_input], mode_train)\n",
        "    return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8C3fm4r6tdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(x, n_out, mode_train):\n",
        "    beta_initialize = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    gamma_initialize = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
        "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_initialize)\n",
        "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_initialize)\n",
        "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
        "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
        "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
        "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
        "    def mean_var():\n",
        "        with tf.control_dependencies([ema_apply_op]):\n",
        "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
        "    mean, var = control_flow_ops.cond(mode_train, mean_var, lambda: (ema_mean, ema_var))\n",
        "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
        "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
        "    return tf.reshape(normed, [-1, n_out])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPomeQMg61f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer(input, weight_shape, bias_shape, mode_train):\n",
        "    value_initialize = (1.0 / weight_shape[0] ** 0.5)\n",
        "    weight_initialize = tf.random_normal_initializer(stddev = value_initialize, seed = None)\n",
        "    bias_initialize = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
        "    w = tf.get_variable(\"w\", weight_shape, initializer=weight_initialize)\n",
        "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_initialize)\n",
        "    return tf.nn.sigmoid(batch_norm((tf.matmul(input, w) + b), weight_shape[1], mode_train))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuq5HnwW642G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(reconstructed, x):\n",
        "    with tf.variable_scope(\"train\"):\n",
        "        train_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(reconstructed, x)), 1))\n",
        "        return train_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAIvq9769F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(cost, learning_rate, beta1, beta2, global_step):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon=1e-08, use_locking=False, name='Adam')\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "    return train_op"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIEYZXv7AUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "n_layers = 5 #----------------------------- Number of Neural Networks Layers.\n",
        "beta1 = 0.9 #------------------------------ The decay rate 1.  \n",
        "beta2 = 0.999 #---------------------------- The decay rate 2.\n",
        "learning_rate = (beta1/n_input) #---------- The learning rate.\n",
        "stop_learning = 1.35 #--------------------- The stop learning point.\n",
        "n_batch = math.ceil(sqrt(sqrt(n_input))) #- Number of selection data in per step.\n",
        "n_backpro = math.ceil(n_input/n_batch) #--- Number of Backpro in per epoch.\n",
        "n_clusters = 10 #--------------------------- Number of clusters.\n",
        "n_diplay = 10 #---------------------------- Number of getting code and runnig the K-Means."
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPCpkiff7Kxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cor, labels_cor = trainSet_correlation.whole_dataset() #-- Allocation of data and labels\n",
        "data_cos, labels_cos = trainSet_cosine.whole_dataset() #------- Allocation of data and labels"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5XoVMB7glv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cor=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cor=[] #------------------------- A list to keep all training evaluations.\n",
        "seeding_cor=[] #--------------------------- A list to keep all steps."
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro0Smij1Jq66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8d78d0cb-3d09-436d-b631-3be040891ac5"
      },
      "source": [
        "with tf.Graph().as_default():    \n",
        "    with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "        x = tf.placeholder(\"float\", [None, n_input])   \n",
        "        mode_train = tf.placeholder(tf.bool)\n",
        "        code = encoder(x, int(n_code), mode_train)\n",
        "        reconstructed = decoder(code, int(n_code), mode_train)\n",
        "        cost = loss(reconstructed, x)\n",
        "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "        train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "        sess = tf.Session()\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        sess.run(init_op)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-5221a4ca5356>:4: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-18 09:14:52,309 WARNING From <ipython-input-26-5221a4ca5356>:4: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-18 09:14:52,329 WARNING From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQVfu2jxJvnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "cc162100-7b6e-4518-e0f2-5d765d3dfea8"
      },
      "source": [
        "# Training cycle\n",
        "epoch = 0\n",
        "while epoch == 0 or new_cost >= stop_learning:\n",
        "    # Fit training with Backpropagation using batch data.\n",
        "    for i in range(n_backpro):\n",
        "        miniData, _ = trainSet_correlation.next_batch(n_batch)\n",
        "        _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                  mode_train:True})       \n",
        "    #------------------------- End of the Optimization ------------------------------\n",
        "    epoch += 1\n",
        "    # Save the results after per 10 epochs.    \n",
        "    if epoch % n_diplay == 0 or new_cost <= stop_learning:\n",
        "        # Getting embedded codes and running K-Means on them.\n",
        "        ae_codes_cor = sess.run(code, feed_dict={x: data_cor, mode_train: False})        \n",
        "        idx_cor = k_means_(ae_codes_cor, n_clusters)\n",
        "        ae_nmi_cor = normalized_mutual_info_score(labels_cor, idx_cor)\n",
        "        ae_nmi_cor = ae_nmi_cor*100\n",
        "        results_cor.append(ae_nmi_cor)    \n",
        "        steps_cor.append(epoch)\n",
        "        loss_cost_cor.append(new_cost)    \n",
        "        print(\"NMI Score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step. \"\n",
        "              .format(ae_nmi_cor, new_cost, epoch))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-93627f484815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fit training with Backpropagation using batch data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_backpro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mminiData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSet_correlation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n\u001b[1;32m      8\u001b[0m                                                                   mode_train:True})       \n",
            "\u001b[0;32m<ipython-input-7-c573112324ab>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlabels_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c573112324ab>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlabels_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 348"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqvowZOTJvsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_cos=[] #--------------------------- A list to keep all NMI scores.\n",
        "loss_cost_cos=[] #------------------------- A list to keep all training evaluations.\n",
        "steps_cos=[] #----------------------------- A list to keep all steps."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgmWSzNJv0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():    \n",
        "    with tf.variable_scope(\"autoencoder_architecture\"):\n",
        "        x = tf.placeholder(\"float\", [None, n_input])   \n",
        "        mode_train = tf.placeholder(tf.bool)\n",
        "        code = encoder(x, int(n_code), mode_train)\n",
        "        reconstructed = decoder(code, int(n_code), mode_train)\n",
        "        cost = loss(reconstructed, x)\n",
        "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "        train_optimizer = training(cost, learning_rate, beta1, beta2, global_step)\n",
        "        sess = tf.Session()\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        sess.run(init_op)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN__LlNYJvxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "85193cbe-4820-4ea9-e0b4-d77557ba8dd1"
      },
      "source": [
        "# Training cycle\n",
        "epoch = 0\n",
        "while epoch == 0 or new_cost >= stop_learning:\n",
        "    # Fit training with backpropagation using batch data.\n",
        "    for i in range(n_backpro):\n",
        "        miniData, _ = trainSet_cosine.next_batch(n_batch)\n",
        "        _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n",
        "                                                                  mode_train: True})       \n",
        "    #------------------------- End of the Optimization ------------------------------\n",
        "    epoch += 1\n",
        "    # Save the results after per 10 epochs.    \n",
        "    if epoch % n_diplay == 0 or new_cost <= stop_learning:\n",
        "        # Getting embedded codes and running K-Means on them.\n",
        "        ae_codes_cos = sess.run(code, feed_dict={x: data_cos, mode_train: False})        \n",
        "        idx_cos = k_means_(ae_codes_cos, n_clusters)\n",
        "        ae_nmi_cos = normalized_mutual_info_score(labels_cos, idx_cos)\n",
        "        ae_nmi_cos = ae_nmi_cos*100\n",
        "        results_cos.append(ae_nmi_cos)    \n",
        "        steps_cos.append(epoch)\n",
        "        loss_cost_cos.append(new_cost)    \n",
        "        print(\"NMI Score for AE is: {:0.2f} and new cost is: {:0.2f} in {:d} step. \"\n",
        "              .format(ae_nmi_cos, new_cost, epoch))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-688d2b6ac11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fit training with backpropagation using batch data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_backpro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mminiData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSet_cosine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         _, new_cost = sess.run([train_optimizer,cost], feed_dict={x: miniData,\n\u001b[1;32m      8\u001b[0m                                                                   mode_train: True})       \n",
            "\u001b[0;32m<ipython-input-7-c573112324ab>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlabels_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c573112324ab>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlabels_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwhole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 245"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3n-GZ7YJvqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "bef011f0-273e-457f-8841-4d245e5cd072"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "plt.figure(figsize=(12,3.5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(steps_cor, loss_cost_cor, label='Cost Trianing for Correlation Distance ', color='#000080', marker='o')\n",
        "plt.plot(steps_cos, loss_cost_cos, label='Cost Trianing for Cosine Distance ', color='#E3CF57', marker='s')\n",
        "plt.xlabel('Number of Epochs.')\n",
        "plt.ylabel('Cost')\n",
        "plt.grid()\n",
        "plt.title('Cost Function Trianing')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(1,2,2)\n",
        "plt.ylim(1, 90)\n",
        "plt.plot(steps_cor, results_cor, label='AE Normalized Correlation Distance ', color='#000080', marker='o')\n",
        "plt.plot(steps_cos, results_cos, label='AE Normalized Cosine Distance ', color='#E3CF57', marker='s')\n",
        "plt.xlabel('Number of Epochs.')\n",
        "plt.ylabel('NMI')\n",
        "plt.grid()\n",
        "plt.title(('NMI of AE Correlation is {:0.2f} \\n and AE Cosine is {:0.2f}').format(ae_nmi_cor, ae_nmi_cos))\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7e0a73dabd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_cor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_cost_cor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cost Trianing for Correlation Distance '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#000080'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_cos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_cost_cos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cost Trianing for Cosine Distance '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#E3CF57'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Epochs.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'steps_cor' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUnvQA9HJvlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origin_label_cos = np.array(trainSet_cosine.whole_dataset()[1]).astype(int)\n",
        "origin_label_cor = np.array(trainSet_correlation.whole_dataset()[1]).astype(int)\n",
        "colors = [('c', '1'),('g', '2'),('m','3')]\n",
        "plt.figure(figsize=(14, 5))\n",
        "for num in range(3):\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.scatter([ae_codes_cor[:,0][i] for i in range(len(origin_label_cor)) if origin_label_cor[i] == num],\n",
        "                [ae_codes_cor[:,1][i] for i in range(len(origin_label_cor)) if origin_label_cor[i] == num],\n",
        "                60, label=str(num+1), color = colors[num][0], marker=colors[num][1])\n",
        "    plt.title('Normalized Correlation Distance with Original Labels.')\n",
        "    plt.xlabel('A representation by AE in 2 dimensions.')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.scatter([ae_codes_cos[:,0][i] for i in range(len(origin_label_cos)) if origin_label_cos[i] == num],\n",
        "                [ae_codes_cos[:,1][i] for i in range(len(origin_label_cos)) if origin_label_cos[i] == num],\n",
        "                60, label=str(num+1), color = colors[num][0], marker=colors[num][1])\n",
        "    plt.title('Normalized Cosine Distance with Original Labels.')\n",
        "    plt.xlabel('A representation by AE in 2 dimensions.')\n",
        "    plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MnaaxS4KLaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colors = [('r', '1'),('b', '2'),('y','3')]\n",
        "plt.figure(figsize=(14, 5))\n",
        "for num in range(3):\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.scatter([ae_codes_cor[:,0][i] for i in range(len(idx_cor)) if idx_cor[i] == num],\n",
        "                [ae_codes_cor[:,1][i] for i in range(len(idx_cor)) if idx_cor[i] == num],\n",
        "                60, label=str(num+1), color = colors[num][0], marker=colors[num][1])\n",
        "    plt.title(('NMI of AE on Correlation is {:0.2f}').format(ae_nmi_cor))\n",
        "    plt.xlabel('Runs K-Means on the representation by AE in 2 dimensions.')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.scatter([ae_codes_cos[:,0][i] for i in range(len(idx_cos)) if idx_cos[i] == num],\n",
        "                [ae_codes_cos[:,1][i] for i in range(len(idx_cos)) if idx_cos[i] == num],\n",
        "                60, label=str(num+1), color = colors[num][0], marker=colors[num][1])\n",
        "    plt.title(('NMI of AE on Cosine is {:0.2f}').format(ae_nmi_cos))\n",
        "    plt.xlabel('Runs K-Means on the representation by AE in 2 dimensions.')\n",
        "    plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szvt_2oYKLWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Autoencoder Clustering on Cosine: ------------ {:0.2f}\".format(ae_nmi_cos))\n",
        "print(\"Autoencoder Clustering on Correlation: ------- {:0.2f}\".format(ae_nmi_cor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ1P4U4kKLVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}