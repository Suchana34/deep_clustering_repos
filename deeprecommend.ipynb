{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeprecommend.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQ5aCwXeohb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X6MENM4ofbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/edited_topics_all_news.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM_OUtsvu5OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1uRT3lRofYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install livelossplot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DVwq0bEofU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as pyplot\n",
        "from livelossplot import PlotLosses\n",
        "#from loss import MSEloss_with_Mask\n",
        "#from model import AutoEncoder\n",
        "#from TestDataset import TestDataset\n",
        "#from TrainDataset import TrainDataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJMkjt9mofS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class MSEloss_with_Mask(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MSEloss_with_Mask,self).__init__()\n",
        "\n",
        "  def forward(self,inputs, targets):\n",
        "    # Masking into a vector of 1's and 0's.\n",
        "    mask = (targets!=0)\n",
        "    mask = mask.float()\n",
        "\n",
        "    # Actual number of ratings.\n",
        "    # Take max to avoid division by zero while calculating loss.\n",
        "    other = torch.Tensor([1.0])\n",
        "    other = other.cuda()\n",
        "    number_ratings = torch.max(torch.sum(mask),other)\n",
        "    error = torch.sum(torch.mul(mask,torch.mul((targets-inputs),(targets-inputs))))\n",
        "    loss = error.div(number_ratings)\n",
        "    return loss[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL7e9E6VofP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def activation(input, type):\n",
        "  \n",
        "    if type.lower()=='selu':\n",
        "        return F.selu(input)\n",
        "    elif type.lower()=='elu':\n",
        "        return F.elu(input)\n",
        "    elif type.lower()=='relu':\n",
        "        return F.relu(input)\n",
        "    elif type.lower()=='relu6':\n",
        "        return F.relu6(input)\n",
        "    elif type.lower()=='lrelu':\n",
        "        return F.leaky_relu(input)\n",
        "    elif type.lower()=='tanh':\n",
        "        return F.tanh(input)\n",
        "    elif type.lower()=='sigmoid':\n",
        "        return F.sigmoid(input)\n",
        "    elif type.lower()=='swish':\n",
        "        return F.sigmoid(input)*input\n",
        "    elif type.lower()=='identity':\n",
        "        return input\n",
        "    else:\n",
        "        raise ValueError(\"Unknown non-Linearity Type\")\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, layer_sizes, nl_type='selu', is_constrained=True, dp_drop_prob=0.0, last_layer_activations=True):\n",
        "        \"\"\"\n",
        "        layer_sizes = size of each layer in the autoencoder model\n",
        "        For example: [10000, 1024, 512] will result in:\n",
        "            - encoder 2 layers: 10000x1024 and 1024x512. Representation layer (z) will be 512\n",
        "            - decoder 2 layers: 512x1024 and 1024x10000.\n",
        "        \n",
        "        nl_type = non-Linearity type (default: 'selu).\n",
        "        is_constrained = If true then the weights of encoder and decoder are tied.\n",
        "        dp_drop_prob = Dropout probability.\n",
        "        last_layer_activations = Whether to apply activation on last decoder layer.\n",
        "        \"\"\"\n",
        "\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.nl_type = nl_type\n",
        "        self.is_constrained = is_constrained\n",
        "        self.dp_drop_prob = dp_drop_prob\n",
        "        self.last_layer_activations = last_layer_activations\n",
        "\n",
        "        if dp_drop_prob>0:\n",
        "            self.drop = nn.Dropout(dp_drop_prob)\n",
        "\n",
        "        self._last = len(layer_sizes) - 2\n",
        "\n",
        "        # Initaialize Weights\n",
        "        self.encoder_weights = nn.ParameterList( [nn.Parameter(torch.rand(layer_sizes[i+1], layer_sizes[i])) for i in range(len(layer_sizes) - 1)  ] )\n",
        "\n",
        "        # \"Xavier Initialization\" ( Understanding the Difficulty in training deep feed forward neural networks - by Glorot, X. & Bengio, Y. )\n",
        "        # ( Values are sampled from uniform distribution )\n",
        "        for weights in self.encoder_weights:\n",
        "            init.xavier_uniform_(weights)\n",
        "\n",
        "        # Encoder Bias\n",
        "        self.encoder_bias = nn.ParameterList( [nn.Parameter(torch.zeros(layer_sizes[i+1])) for i in range(len(layer_sizes) - 1) ] )\n",
        "\n",
        "        reverse_layer_sizes = list(reversed(layer_sizes)) \n",
        "        # reversed returns iterator\n",
        "\n",
        "\n",
        "        # Decoder Weights\n",
        "        if is_constrained == False:\n",
        "            self.decoder_weights = nn.ParameterList( [nn.Parameter(torch.rand(reverse_layer_sizes[i+1], reverse_layer_sizes[i])) for i in range(len(reverse_layer_sizes) - 1) ] )\n",
        "\n",
        "            for weights in self.decoder_weights:\n",
        "                init.xavier_uniform_(weights)\n",
        "\n",
        "        self.decoder_bias = nn.ParameterList( [nn.Parameter(torch.zeros(reverse_layer_sizes[i+1])) for i in range(len(reverse_layer_sizes) - 1) ] )\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self,x):\n",
        "        for i,w in enumerate(self.encoder_weights):\n",
        "            x = F.linear(input=x, weight = w, bias = self.encoder_bias[i] )\n",
        "            x = activation(input=x, type=self.nl_type)\n",
        "\n",
        "        # Apply Dropout on the last layer\n",
        "        if self.dp_drop_prob > 0:\n",
        "            x = self.drop(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def decode(self,x):\n",
        "        if self.is_constrained == True:\n",
        "            # Weights are tied\n",
        "            for i,w in zip(range(len(self.encoder_weights)),list(reversed(self.encoder_weights))):\n",
        "                x = F.linear(input=x, weight=w.t(), bias = self.decoder_bias[i] )\n",
        "                x = activation(input=x, type=self.nl_type if i != self._last or self.last_layer_activations else 'identity')\n",
        "\n",
        "        else:\n",
        "\n",
        "            for i,w in enumerate(self.decoder_weights):\n",
        "                x = F.linear(input=x, weight = w, bias = self.decoder_weights[i])\n",
        "                x = activation(input=x, type=self.nl_type if i != self._last or self.last_layer_activations else 'identity')\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self,x):\n",
        "        # Forward Pass\n",
        "        return self.decode(self.encode(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYvquPIGsj5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "# move articles to an array\n",
        "articles = df.processed_content.values\n",
        "\n",
        "# move article section names to an array\n",
        "sections = df.processed_topic.values\n",
        "\n",
        "\n",
        "# shuffle these three arrays \n",
        "articles, sections = shuffle(articles, sections, random_state=4)\n",
        "\n",
        "# split the shuffled articles into two arrays\n",
        "n = 300\n",
        "\n",
        "# one will have all but the last 10 articles -- think of this as your training set/corpus \n",
        "X_train = articles[:-n]\n",
        "X_train_sections = sections[:-n]\n",
        "\n",
        "# the other will have those last 10 articles -- think of this as your test set/corpus \n",
        "X_test = articles[-n:]\n",
        "X_test_sections = sections[-n:]\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "X_test_df = pd.DataFrame(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pBqB0-0v2qD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7dd96c60-49e7-4386-923b-58def618dd41"
      },
      "source": [
        "data = X_train_df.iloc[1:,:]\n",
        "#transformat = transforms.Compose([transforms.ToTensor()])\n",
        "#data = data.transform(transformat)\n",
        "data"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delhi chines troop wednesday complet disengag ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>agre protect youngl parcel parenthood video fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>actor amit sadh reveal contempl suicid eventu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>padmini prasad practic gynaecologist obstetric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>china report tuesday coronavirus case mainland...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>islamabad pakistani court dismiss ident petit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>karwar week bhatkal town uttara kannada distri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>gunmen open belong afghan attorney general off...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>delhi india retail inflat pick june push price...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>mumbai take second watch trailer shakuntala de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>973 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0\n",
              "1    delhi chines troop wednesday complet disengag ...\n",
              "2    agre protect youngl parcel parenthood video fl...\n",
              "3    actor amit sadh reveal contempl suicid eventu ...\n",
              "4    padmini prasad practic gynaecologist obstetric...\n",
              "5    china report tuesday coronavirus case mainland...\n",
              "..                                                 ...\n",
              "969  islamabad pakistani court dismiss ident petit ...\n",
              "970  karwar week bhatkal town uttara kannada distri...\n",
              "971  gunmen open belong afghan attorney general off...\n",
              "972  delhi india retail inflat pick june push price...\n",
              "973  mumbai take second watch trailer shakuntala de...\n",
              "\n",
              "[973 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSzU20bQwWhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, train_file, transform=None):\n",
        "        self.data = X_train_df\n",
        "        self.data = self.data.iloc[:]\n",
        "        self.transform = transform\n",
        "        \n",
        "        if transform is not None:\n",
        "            self.data = self.transform(np.array(self.data))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "    \n",
        "    def __getitem__(self, ind):\n",
        "        user_vector = self.data.data[0][ind]\n",
        "        \n",
        "        return user_vector"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6KRVh5wWnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, test_file, transform=None):\n",
        "        self.data = X_test_df\n",
        "        self.data = self.data.iloc[:]\n",
        "        self.transform = transform\n",
        "        \n",
        "        if transform is not None:\n",
        "            self.data = self.transform(np.array(self.data))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "    \n",
        "    def __getitem__(self, ind):\n",
        "        user_vector = self.data.data[0][ind]\n",
        "        \n",
        "        return user_vector"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5T_-XLLofNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "39b33ead-f281-45d5-e001-4216ceebaad0"
      },
      "source": [
        "transformations = transforms.Compose([transforms.ToTensor()])\n",
        "train_dat = TrainDataset(X_train_df, transformations)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1d5b2b05d1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtransformations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-86d57581568a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_file, transform)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E08iT6quzYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training Length: \", train_dat.__len__())\n",
        "print(\"6th User Ratings: \", train_dat.__getitem__(7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YDo0vgduzd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dat = TestDataset('test.csv', transformations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyiiLd5suza_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Testing Length: \", test_dat.__len__())\n",
        "print(\"6th User Ratings: \", test_dat.__getitem__(4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4So-VXvu7SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataloader\n",
        "\n",
        "train_dl = DataLoader(dataset=train_dat, batch_size = 128, shuffle=True, num_workers = 1)\n",
        "test_dl = DataLoader(dataset=test_dat, batch_size=128, shuffle=True, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hMu4Zowu7Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking for availability of GPU\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDGyG-4IuzWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training the Model\n",
        "layer_sizes = [9559, 512, 512, 1024]\n",
        "model = AutoEncoder(layer_sizes=layer_sizes, nl_type='selu', is_constrained=True, dp_drop_prob=0.0, last_layer_activations=False)\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxeJVrjHvMlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "criterion = MSEloss_with_Mask()\n",
        "criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VuW8dLbvMra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR78AFqLvMoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting the Model\n",
        "\n",
        "# hl1_tr_loss = []\n",
        "# hl2_val_loss = []"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ANgBE-vMjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, criterion, optimizer, train_dl, test_dl, num_epochs=40):\n",
        "  # We will run for 40 epochs\n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss, valid_loss = [], []\n",
        "    logs = {}\n",
        "    prefix = ''\n",
        "\n",
        "    # Training Part\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_dl, 0):\n",
        "      # Get the inputs\n",
        "      inputs = labels = data\n",
        "      inputs = inputs.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "      inputs = inputs.float()\n",
        "      labels = labels.float()\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(inputs)\n",
        "      outputs = outputs.cuda()\n",
        "      loss = criterion(outputs,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      ## -> Iterative Dense Output Re-feeding <- ##\n",
        "      \n",
        "      # Add a \"for\" loop to iterate as much you want\n",
        "      \n",
        "      # Zero the gradiants\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Important -> detach() the output, to avoid unecessary construction of \n",
        "      # the computational graph\n",
        "      outputs = model(outputs.detach())\n",
        "      outputs = outputs.cuda()\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "      logs[prefix + 'MMSE loss'] = loss.item()\n",
        "\n",
        "    for i, data in enumerate(test_dl, 0):\n",
        "      model.eval()\n",
        "      inputs = labels = data\n",
        "      inputs = inputs.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "      inputs = inputs.float()\n",
        "      labels = labels.float()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      outputs = outputs.cuda()\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      valid_loss.append(loss.item())\n",
        "      prefix = 'val_'\n",
        "      logs[prefix + 'MMSE loss'] = loss.item()\n",
        "\n",
        "    lr2_tr_loss.append(np.mean(train_loss))\n",
        "    lr2_val_loss.append(np.mean(valid_loss))\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "    print (\"Epoch:\", epoch+1, \" Training Loss: \", np.mean(train_loss), \" Valid Loss: \", np.mean(valid_loss))\n",
        "    if epoch == num_epochs -1:\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaQQKMbyvz_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = train(model, criterion, optimizer, train_dl, test_dl, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiqmAHSjv0Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ep = np.arange(1,41)\n",
        "plt.plot(ep, hl1_tr_loss)\n",
        "plt.plot(ep, hl2_tr_loss)\n",
        "plt.ylim(bottom=0, top=2)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MMSE loss\")\n",
        "plt.legend([\"Hidden layer 1024\", \"Hidden Layer 256\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Krj9fu9v0HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ep = np.arange(1,41)\n",
        "plt.plot(ep, hl1_val_loss)\n",
        "plt.plot(ep, hl2_val_loss)\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MMSE loss\")\n",
        "plt.legend([\"Hidden layer 1024\", \"Hidden Layer 256\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKuyvBmHv0CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input Batch\n",
        "\n",
        "next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oXNZbfVvz9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output of a batch after training\n",
        "out"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}